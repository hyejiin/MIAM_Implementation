{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f47941c-3051-44ef-a528-2f1091461ac2",
   "metadata": {},
   "source": [
    "###  PyTorch implementation of the paper : Multi-view Integration Learning for Irregularly-sampled Clinical Time Series (MIAM) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276584f8-e2a1-4b7c-854b-8fab6f0c6574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_curve, roc_auc_score\n",
    "\n",
    "import tensorflow as tf\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "from attention_graph_util import *\n",
    "import copy\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_recall_curve\n",
    "from sklearn.model_selection import KFold\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f602cfec-b747-4bdd-b8d5-33275aaf5382",
   "metadata": {},
   "source": [
    "### Data Preprocessing and Transformation to MIAM Format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16eb6577-5572-4778-b1d5-0df0fccfe8f0",
   "metadata": {},
   "source": [
    "Using PhysioNet 2012 Challenge dataset, In-Hospital Mortality Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7c3ef393-d201-415a-9010-2e2e1615ef70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define data folders and outcomes paths for each set\n",
    "data_folder_a = \"/media/usr/HDD/Data/EHR/Challenge_2012/set-a\"\n",
    "data_folder_b = \"/media/usr/HDD/Data/EHR/Challenge_2012/set-b\"\n",
    "data_folder_c = \"/media/usr/HDD/Data/EHR/Challenge_2012/set-c\"\n",
    "outcomes_path_a = \"/media/usr/HDD/Data/EHR/Challenge_2012/Outcomes-a.txt\"\n",
    "outcomes_path_b = \"/media/usr/HDD/Data/EHR/Challenge_2012/Outcomes-b.txt\"\n",
    "outcomes_path_c = \"/media/usr/HDD/Data/EHR/Challenge_2012/Outcomes-c.txt\"\n",
    "\n",
    "def load_txt_data(folder_path):\n",
    "    data_dict = {}\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.txt'):\n",
    "            record_id = file_name.split('.')[0]\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            df = pd.read_csv(file_path, sep=',')\n",
    "            data_dict[record_id] = df\n",
    "    return data_dict\n",
    "\n",
    "def load_outcomes(outcomes_path):\n",
    "    outcomes_df = pd.read_csv(outcomes_path, sep=',')\n",
    "    outcomes_df.set_index('RecordID', inplace=True)\n",
    "    return outcomes_df\n",
    "\n",
    "\n",
    "\n",
    "from scipy.stats.mstats import winsorize\n",
    "\n",
    "def apply_winsorize(data_dict):\n",
    "    for record_id, df in data_dict.items():\n",
    "        for column in df.columns:\n",
    "            # 열이 비어 있지 않은지 확인\n",
    "            if df[column].notna().sum() > 0:\n",
    "                df[column] = winsorize(df[column], limits=[0.02, 0.02])\n",
    "    return data_dict\n",
    "\n",
    "\n",
    "def z_normalize(data_dict, mean_dict=None, std_dict=None, is_train=True):\n",
    "    if is_train:\n",
    "        mean_dict = {}\n",
    "        std_dict = {}\n",
    "        for record_id, df in data_dict.items():\n",
    "            for column in df.columns:\n",
    "                if column not in mean_dict:\n",
    "                    mean_dict[column] = df[column].mean()\n",
    "                    std_dict[column] = df[column].std()\n",
    "\n",
    "    for record_id, df in data_dict.items():\n",
    "        for column in df.columns:\n",
    "            if std_dict[column] != 0:\n",
    "                df[column] = (df[column] - mean_dict[column]) / std_dict[column]\n",
    "    \n",
    "    return data_dict, mean_dict, std_dict\n",
    "\n",
    "\n",
    "\n",
    "# def preprocess_data_with_fixed_variables(data_dict, variable_list):\n",
    "#     processed_data = {}\n",
    "#     for record_id, df in data_dict.items():\n",
    "#         df = df.groupby(['Time', 'Parameter'], as_index=False).mean()\n",
    "#         df_pivot = df.pivot(index='Time', columns='Parameter', values='Value')\n",
    "#         df_pivot = df_pivot.reindex(columns=variable_list, fill_value=np.nan)\n",
    "#         processed_data[record_id] = df_pivot.reset_index(drop=True)\n",
    "#     return processed_data\n",
    "\n",
    "variable_list = [\n",
    "    'DiasABP', 'NIDiasABP', 'FiO2', 'GCS',\n",
    "'HR', 'MAP', 'NIMAP', 'PaCO2', 'PaO2',\n",
    "'RespRate', 'SysABP', 'NISysABP', 'Temp', 'Urine',\n",
    "'ALP', 'ALT', 'AST', 'Albumin',\n",
    "'BUN', 'Bilirubin', 'Cholesterol', 'Creatinine', 'Glucose', 'HCO3', 'HCT',\n",
    "'K', 'Lactate', 'Mg', 'Na', 'Platelets',\n",
    "'SaO2', 'TropI', 'TropT', 'WBC', 'pH']\n",
    "\n",
    "\n",
    "def preprocess_data_with_fixed_variables(data_dict, variable_list):\n",
    "    processed_data = {}\n",
    "    for record_id, df in data_dict.items():\n",
    "        # 'RecordID', 'Age', 'Gender', 'Height', 'ICUType' 등 일반 정보 제외\n",
    "        df = df[~df['Parameter'].isin(['RecordID', 'Age', 'Gender', 'Height', 'ICUType', 'Weight'])]\n",
    "        \n",
    "        # 'Time'과 'Parameter'로 groupby 후 평균을 계산해 중복 해결\n",
    "        df = df.groupby(['Time', 'Parameter'], as_index=False).mean()\n",
    "\n",
    "        # 피벗 테이블을 만들어 변수들을 열로 변환\n",
    "        df_pivot = df.pivot(index='Time', columns='Parameter', values='Value')\n",
    "\n",
    "        # 변수 리스트에 맞춰 열을 정렬하고, 누락된 변수는 NaN으로 채움\n",
    "        df_pivot = df_pivot.reindex(columns=variable_list, fill_value=np.nan)\n",
    "\n",
    "        # 처리된 데이터를 사전에 저장\n",
    "        processed_data[record_id] = df_pivot.reset_index(drop=True)\n",
    "    \n",
    "    return processed_data\n",
    "\n",
    "\n",
    "\n",
    "def map_outcomes(data_dict, outcomes_df):\n",
    "    labeled_data = {}\n",
    "    for record_id, df in data_dict.items():\n",
    "        if int(record_id) in outcomes_df.index:\n",
    "            outcome = outcomes_df.loc[int(record_id)]\n",
    "            labeled_data[record_id] = (df, outcome)\n",
    "    return labeled_data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "cf44e0cc-752d-48d7-a4aa-2b1a23ae1de3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Assuming all previous functions and model definitions are included\n",
    "\n",
    "# Load data for each set\n",
    "data_a = load_txt_data(data_folder_a)\n",
    "data_b = load_txt_data(data_folder_b)\n",
    "data_c = load_txt_data(data_folder_c)\n",
    "\n",
    "# Load outcomes for each set\n",
    "outcomes_a = load_outcomes(outcomes_path_a)\n",
    "outcomes_b = load_outcomes(outcomes_path_b)\n",
    "outcomes_c = load_outcomes(outcomes_path_c)\n",
    "\n",
    "data_a = preprocess_data_with_fixed_variables(data_a, variable_list)\n",
    "data_b = preprocess_data_with_fixed_variables(data_b, variable_list)\n",
    "data_c = preprocess_data_with_fixed_variables(data_c, variable_list)\n",
    "\n",
    "# Preprocess the data\n",
    "data_a = apply_winsorize(data_a)\n",
    "data_a, mean_dict, std_dict = z_normalize(data_a, is_train=True)\n",
    "data_b = apply_winsorize(data_b)\n",
    "data_b, _, _ = z_normalize(data_b, mean_dict, std_dict, is_train=False)\n",
    "data_c = apply_winsorize(data_c)\n",
    "data_c, _, _ = z_normalize(data_c, mean_dict, std_dict, is_train=False)\n",
    "\n",
    "\n",
    "\n",
    "# data_a = zero_imputation(data_a)\n",
    "# data_b = zero_imputation(data_b)\n",
    "# data_c = zero_imputation(data_c)\n",
    "\n",
    "data_a_labeled = map_outcomes(data_a, outcomes_a)\n",
    "data_b_labeled = map_outcomes(data_b, outcomes_b)\n",
    "data_c_labeled = map_outcomes(data_c, outcomes_c)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "b9318b17-3d63-4ff9-b0ae-0f6dfa79df05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patients in filtered data_a: 1416\n",
      "Number of patients in filtered data_b: 1411\n",
      "Number of patients in filtered data_c: 1424\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of patients in filtered data_a:\", len(data_a_labeled))\n",
    "print(\"Number of patients in filtered data_b:\", len(data_b_labeled))\n",
    "print(\"Number of patients in filtered data_c:\", len(data_c_labeled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "bacb853f-d890-45d1-8d89-bccc44ca66e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum time-series length in data_a: 202\n",
      "Maximum time-series length in data_b: 185\n",
      "Maximum time-series length in data_c: 214\n"
     ]
    }
   ],
   "source": [
    "# Function to find the maximum time-series length in a dataset\n",
    "def get_max_time_series_length(data_set):\n",
    "    max_length = max(patient_data[0].shape[0] for patient_data in data_set.values())  # patient_data[0] is the DataFrame\n",
    "    return max_length\n",
    "\n",
    "# Calculate and print the maximum time-series length for each dataset\n",
    "max_length_a = get_max_time_series_length(data_a_labeled)\n",
    "max_length_b = get_max_time_series_length(data_b_labeled)\n",
    "max_length_c = get_max_time_series_length(data_c_labeled)\n",
    "\n",
    "print(\"Maximum time-series length in data_a:\", max_length_a)\n",
    "print(\"Maximum time-series length in data_b:\", max_length_b)\n",
    "print(\"Maximum time-series length in data_c:\", max_length_c)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "b4491a98-672a-45e5-b058-524786635df9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(616, 3635, 5.900974025974026)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure that outcomes_a.index is a string\n",
    "outcomes_a.index = outcomes_a.index.astype(str)\n",
    "outcomes_b.index = outcomes_b.index.astype(str)\n",
    "outcomes_c.index = outcomes_c.index.astype(str)\n",
    "\n",
    "# Filter outcomes based on the existing keys in filtered_data_a (which are already strings)\n",
    "filtered_outcomes_a = outcomes_a.loc[outcomes_a.index.isin(filtered_data_a.keys())]\n",
    "filtered_outcomes_b = outcomes_b.loc[outcomes_b.index.isin(filtered_data_b.keys())]\n",
    "filtered_outcomes_c = outcomes_c.loc[outcomes_c.index.isin(filtered_data_c.keys())]\n",
    "\n",
    "# Concatenate the filtered outcomes\n",
    "filtered_outcomes = pd.concat([filtered_outcomes_a, filtered_outcomes_b, filtered_outcomes_c])\n",
    "\n",
    "# Count positive and negative outcomes\n",
    "positive_count = filtered_outcomes['In-hospital_death'].sum()\n",
    "negative_count = len(filtered_outcomes) - positive_count\n",
    "\n",
    "# Calculate the imbalance ratio\n",
    "imbalance_ratio = negative_count / positive_count\n",
    "\n",
    "# Display the results\n",
    "positive_count, negative_count, imbalance_ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "8569ed25-f0b1-4bc1-a49b-ea9a4829ff2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Rate: 85.61%\n"
     ]
    }
   ],
   "source": [
    "def calculate_missing_rate(data_dict):\n",
    "    total_values = 0\n",
    "    missing_values = 0\n",
    "\n",
    "    # Loop over each record (patient) in the dataset\n",
    "    for record_id, (df, outcome) in data_dict.items():  # Access the first element in the tuple (df)\n",
    "        total_values += df.size  # Total number of values (cells) in the DataFrame\n",
    "        missing_values += df.isna().sum().sum()  # Count the NaN values as missing\n",
    "\n",
    "    missing_rate = (missing_values / total_values) * 100\n",
    "    return missing_rate\n",
    "\n",
    "# Assuming data_a_labeled is the dataset after loading and preprocessing\n",
    "missing_rate = calculate_missing_rate(data_a_labeled)\n",
    "print(f\"Missing Rate: {missing_rate:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "8908300f-153b-4fbf-b85d-1180a2c413b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(variable_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121ceb75-40b2-499a-a84e-7a1695fb2081",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Data Differences from paper \n",
    "\n",
    "- Maximum time series length: 214 (The paper says \"The number of irregular time points ranged from 1 to 202\")\n",
    "- Positive_counts, negative_counts: 616, 3635 (in paper, 554 positive, 3,443 negative)\n",
    "- Number of patients: 4251 (in paper, 3,997)\n",
    "- Missing Rate : 85.61% (in paper, 80.5%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a3051a-6c1a-4ef2-962e-ab0bb82f898b",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "eeb078c4-7890-4959-9b78-e971ec169438",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Multi_Duration_Pipeline_Residual(nn.Module):\n",
    "    def __init__(self, input_dim, d_model, d_ff, num_stack, num_heads, max_length, n_iter):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_iter = n_iter\n",
    "\n",
    "        # Embeddings\n",
    "        self.obs_embed = Embedder(input_dim, d_model)\n",
    "        self.mask_embed = Embedder(input_dim, d_model)\n",
    "        self.deltas_embed = Embedder(input_dim, d_model)\n",
    "\n",
    "        # Positional Encoding\n",
    "        self.pe = PositionalEncoder_TimeDescriptor(d_model, max_length)\n",
    "\n",
    "        # Encoding blocks\n",
    "        self.obs_encoding_block = Encoding_Block(d_model, max_length, num_heads, d_ff, num_stack)\n",
    "        self.mask_encoding_block = Encoding_Block(d_model, max_length, num_heads, d_ff, num_stack)\n",
    "        self.deltas_encoding_block = Encoding_Block(d_model, max_length, num_heads, d_ff, num_stack)\n",
    "        self.comb_encoding_block = Encoding_Block(d_model, max_length, num_heads, d_ff, num_stack)\n",
    "        self.missing_comb_encoding_block = Encoding_Block(d_model, max_length, num_heads, d_ff, num_stack)\n",
    "\n",
    "        # Decoder\n",
    "        obs_embed_weight = self.obs_embed.embed.weight\n",
    "        n, v = obs_embed_weight.size()\n",
    "        self.decoder = nn.Linear(n, v, bias=False)\n",
    "        self.decoder.weight.data = obs_embed_weight.transpose(1, 0)\n",
    "        self.decoder_bias = nn.Parameter(torch.zeros(v))\n",
    "\n",
    "\n",
    "        \n",
    "        self.los_classifier = nn.Sequential(\n",
    "            nn.Linear(d_model * 2, d_model),\n",
    "            nn.BatchNorm1d(d_model),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(d_model, 1),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(d_model * 2, d_model),\n",
    "            nn.BatchNorm1d(d_model),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(d_model, 1),\n",
    "        )\n",
    "\n",
    "        self.classifier2 = nn.Sequential(\n",
    "            nn.Linear(input_dim * 2, input_dim),\n",
    "            nn.BatchNorm1d(input_dim),\n",
    "            # nn.LeakyReLU(),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(input_dim, 1))\n",
    "\n",
    "        self.time_encoding_block = Encoding_Block(d_model, 3, num_heads, d_ff, num_stack)\n",
    "        self.reset_parameters()\n",
    "\n",
    "        self.lin_clsf = nn.Sequential(\n",
    "            nn.Linear(d_model*2, 1),\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for weight in self.parameters():\n",
    "            if len(weight.size()) == 1:\n",
    "                continue\n",
    "            stv = 1. / math.sqrt(weight.size(1))\n",
    "            nn.init.uniform_(weight, -stv, stv)\n",
    "\n",
    "        \n",
    "    def forward(self, data, mask, times, deltas, attn_mask):\n",
    "        \"\"\"\n",
    "        :param src: Batch x Max_seq_len x Variable\n",
    "        :param mask: Batch x Max_seq_len x Max_seq_len\n",
    "        \"\"\"\n",
    "\n",
    "        # make attn_mask\n",
    "        batch_size, seq_len, var_num = data.size()\n",
    "        attn_mask = attn_mask.unsqueeze(1)\n",
    "        attn_mask = attn_mask.expand(batch_size, seq_len, seq_len)\n",
    "\n",
    "        # Datas\n",
    "        d_z = data#[:, 0, :, :]\n",
    "\n",
    "        # Input embedding\n",
    "        x_z = self.obs_embed(d_z)\n",
    "        m = self.mask_embed(mask)\n",
    "        d = self.deltas_embed(deltas)\n",
    "\n",
    "        # Positional encoding\n",
    "        x_z, m, d = self.pe(x_z, m, d, times)\n",
    "\n",
    "        # obs_mha, mask_mha, delta_mha\n",
    "        x_z = self.obs_encoding_block(x_z, x_z, attn_mask)\n",
    "        x_s = x_z\n",
    "        m = self.mask_encoding_block(m, m, attn_mask)\n",
    "        d = self.deltas_encoding_block(d, d, attn_mask)\n",
    "        missing_comb_z = self.missing_comb_encoding_block(d, m, attn_mask)\n",
    "\n",
    "\n",
    "        # Attention Distillation\n",
    "        for n in range(self.n_iter):\n",
    "            comb_z = self.comb_encoding_block(missing_comb_z, x_z, attn_mask)\n",
    "            x_z = self.obs_encoding_block(comb_z, x_z, attn_mask)\n",
    "\n",
    "\n",
    "        \"\"\"Imputation Part\"\"\"\n",
    "        # Input Embedding\n",
    "        x_mskd = self.obs_embed(d_z.to(data.device))\n",
    "        m_mskd = self.mask_embed(mask.to(data.device))\n",
    "        d_mskd = self.deltas_embed(deltas)\n",
    "\n",
    "        # Positional encoding\n",
    "        x_mskd, m_mskd, d_mskd = self.pe(x_mskd, m_mskd, d_mskd, times)\n",
    "\n",
    "        # Masked MHA\n",
    "        x_d = self.obs_encoding_block(x_mskd, x_mskd, attn_mask)\n",
    "\n",
    "        # Encoder-decoder Attention\n",
    "        x_d = self.obs_encoding_block(x_z, x_d, attn_mask)\n",
    "        x_final = x_d + x_z\n",
    "\n",
    "        x_dd = self.decoder(x_final) + self.decoder_bias\n",
    "\n",
    "        # Classification\n",
    "        combine = 1\n",
    "        x_avg = x_z.mean(dim=1)\n",
    "        m_avg = missing_comb_z.mean(dim=1)#m_final.mean(dim=1)\n",
    "        x_m_cat = torch.stack((x_avg, m_avg), 1).reshape([x_avg.shape[0], -1])\n",
    "        out = self.classifier(x_m_cat)\n",
    "        reg_out = self.los_classifier(x_m_cat)\n",
    "        y = torch.sigmoid(out).squeeze(-1)\n",
    "        return reg_out.squeeze(-1), y, x_dd# reg_out out.squeeze(-1) # y\n",
    "\n",
    "\n",
    "class Encoding_Block(nn.Module):\n",
    "    def __init__(self, d_model, max_length, num_heads, d_ff, num_stack):\n",
    "        super().__init__()\n",
    "\n",
    "        self.N = num_stack\n",
    "\n",
    "        self.layers = get_clones(EncoderLayer(d_model, max_length, num_heads, d_ff), num_stack)\n",
    "        self.norm = Norm(d_model)\n",
    "\n",
    "    def forward(self, q, k, attn_mask):\n",
    "        # MHA Encoding\n",
    "        for i in range(self.N):\n",
    "            q, k = self.layers[i](q, k, attn_mask)\n",
    "\n",
    "        # Normalize\n",
    "        encoded_data = self.norm(q)\n",
    "        return encoded_data\n",
    "\n",
    "class Embedder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model):\n",
    "        super().__init__()\n",
    "        # self.embed = nn.Embedding(vocab_size, d_model)\n",
    "        self.embed = nn.Linear(vocab_size, d_model)\n",
    "        # self.embed = nn.Sequential(\n",
    "        #     nn.Linear(vocab_size, 32),\n",
    "        #     # nn.BatchNorm1d(128),\n",
    "        #     nn.LeakyReLU(),\n",
    "        #     nn.Linear(32, d_model),\n",
    "        # )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embed(x)\n",
    "\n",
    "class PositionalEncoder_TimeDescriptor(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_len):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "    def get_sinusoid_encoding_table(self, seq_len, d_model):\n",
    "        def cal_angle(position, hid_idx):\n",
    "            return position / np.power(self.max_seq_len, 2 * (hid_idx // 2) / d_model)\n",
    "\n",
    "        def get_posi_angle_vec(position):\n",
    "            return [cal_angle(position, hid_j) for hid_j in range(d_model)]\n",
    "\n",
    "        sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in range(seq_len)])\n",
    "\n",
    "        # Apply sin to even indices, cos to odd indices\n",
    "        sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])  # dim 2i\n",
    "        sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])  # dim 2i+1\n",
    "        return torch.FloatTensor(sinusoid_table)\n",
    "\n",
    "    def time_encoding(self, t, seq_len):\n",
    "        batch_size = t.size(0)\n",
    "        pe = self.get_sinusoid_encoding_table(seq_len, self.d_model)\n",
    "        pe = pe.unsqueeze(0).expand(batch_size, -1, -1)  # Expand to shape [batch_size, seq_len, d_model]\n",
    "        return pe\n",
    "\n",
    "    def forward(self, x, m, delta, t):\n",
    "        x = x * math.sqrt(self.d_model)\n",
    "        m = m * math.sqrt(self.d_model)\n",
    "        delta = delta * math.sqrt(self.d_model)\n",
    "\n",
    "        seq_len = x.size(1)  # Get sequence length\n",
    "        pos = self.time_encoding(t, seq_len)  # Pass t and seq_len\n",
    "\n",
    "        # Ensure pos is moved to the same device as x\n",
    "        pos = pos.to(x.device)  # Move pos to the same device as x (e.g., GPU if x is on GPU)\n",
    "\n",
    "        # Apply position encoding to x, m, delta\n",
    "        x = x + Variable(pos, requires_grad=False)\n",
    "        m = m + Variable(pos, requires_grad=False)\n",
    "        delta = delta + Variable(pos, requires_grad=False)\n",
    "\n",
    "        return x, m, delta\n",
    "\n",
    "    \n",
    "\n",
    "def get_clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])\n",
    "\n",
    "class Norm(nn.Module):\n",
    "    def __init__(self, d_model, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.size = d_model\n",
    "\n",
    "        # create two learnable parameters to calibrate normalisation\n",
    "        self.alpha = nn.Parameter(torch.ones(self.size))\n",
    "        self.bias = nn.Parameter(torch.zeros(self.size))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        norm = self.alpha * (x - x.mean(dim=-1, keepdim=True)) \\\n",
    "               / (x.std(dim=-1, keepdim=True) + self.eps) + self.bias\n",
    "        return norm\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, heads, d_model, dropout=0.2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_k = d_model // heads\n",
    "        self.h = heads\n",
    "\n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.out = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, q, k, v, tp, mask=None):\n",
    "        bs = q.size(0)  # Batch size\n",
    "        seq_len = q.size(2)  # Sequence length\n",
    "\n",
    "        # Linear transformations and split into h heads\n",
    "        k = self.k_linear(k).view(bs, -1, self.h, self.d_k)\n",
    "        q = self.q_linear(q).view(bs, -1, self.h, self.d_k)\n",
    "        v = self.v_linear(v).view(bs, -1, self.h, self.d_k)\n",
    "\n",
    "        # Transpose to get dimensions bs * h * seq_len * d_k\n",
    "        k = k.transpose(1, 2)  # [bs, h, seq_len, d_k]\n",
    "        q = q.transpose(1, 2)  # [bs, h, seq_len, d_k]\n",
    "        v = v.transpose(1, 2)  # [bs, h, seq_len, d_k]\n",
    "\n",
    "        # Adjust the mask to match sequence length\n",
    "        if mask is not None:\n",
    "            if mask.dim() == 2:  # If mask is [bs, seq_len], unsqueeze and repeat\n",
    "                mask = mask.unsqueeze(1).unsqueeze(2)  # Convert to [bs, 1, 1, seq_len]\n",
    "            elif mask.dim() == 3:  # If mask is [bs, seq_len, seq_len]\n",
    "                mask = mask.unsqueeze(1)  # Convert to [bs, 1, seq_len, seq_len]\n",
    "\n",
    "            # Now slice the mask to match the sequence length\n",
    "            seq_len = q.size(2)\n",
    "            mask = mask[:, :, :seq_len, :seq_len]  # Slice to fit the seq_len of q, k, and v\n",
    "\n",
    "            # Expand mask to match the batch size (bs) and number of heads (self.h)\n",
    "            mask = mask.expand(bs, self.h, seq_len, seq_len)\n",
    "\n",
    "        # Calculate attention scores using the adjusted mask\n",
    "        scores = attention(q, k, v, self.d_k, mask, self.dropout)\n",
    "        if tp == 1:\n",
    "            scores = scores.transpose(2, 3)\n",
    "\n",
    "        # Concatenate heads and put through final linear layer\n",
    "        concat = scores.transpose(1, 2).contiguous().view(bs, -1, self.d_model)\n",
    "        output = self.out(concat)\n",
    "\n",
    "        return output\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        # We set d_ff as a default to 2048\n",
    "        self.linear_1 = nn.Linear(d_model, d_ff)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear_2 = nn.Linear(d_ff, d_model)\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(F.relu(self.linear_1(x)))\n",
    "        x = self.linear_2(x)\n",
    "        return x\n",
    "\n",
    "def attention(q, k, v, d_k, mask=None, dropout=None):\n",
    "    \"\"\"\n",
    "    :param q: Batch x n_head x max_seq_len x variable\n",
    "    :param k: Batch x n_head x max_seq_len x variable\n",
    "    :param v: Batch x n_head x max_seq_len x variable\n",
    "    :param d_k:\n",
    "    :param mask: Batch x n_had x max_seq_len x max_seq_len\n",
    "    :param dropout:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k)  # [Batch x n_head x max_seq_len x max_seq_len]\n",
    "    #print(f'scores shape: {scores.shape}, mask shape: {mask.shape}')\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask, -1e9)\n",
    "    scores = F.softmax(scores, dim=-1)\n",
    "\n",
    "    if dropout is not None:\n",
    "        scores = dropout(scores)\n",
    "\n",
    "    output = torch.matmul(scores, v)\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, max_length, heads, d_ff, dropout=0):\n",
    "        super().__init__()\n",
    "        self.norm_q = Norm(d_model)\n",
    "        self.norm_k = Norm(d_model)\n",
    "        self.norm_q_attn = Norm(d_model)\n",
    "\n",
    "        self.attn = MultiHeadAttention(heads, d_model)\n",
    "        self.time_attn = MultiHeadAttention(heads, d_model)\n",
    "        self.var_attn = MultiHeadAttention(heads, d_model)\n",
    "\n",
    "        self.ff = FeedForward(d_model, d_ff)\n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "        self.dropout_2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.cat_lin = nn.Linear(128, 64)\n",
    "\n",
    "    def forward(self, q, k, mask):\n",
    "        q2 = self.norm_q(q)\n",
    "        k2 = self.norm_k(k)\n",
    "        q = q + self.dropout_1(self.attn(q2, k2, k2, 0, mask))\n",
    "        q2 = self.norm_q_attn(q)\n",
    "        q = q + self.dropout_2(self.ff(q2))\n",
    "\n",
    "        return q, k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "f2732e32-a6c8-46bb-b8e9-aced4030336d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Multi_Duration_Pipeline_Residual(nn.Module):\n",
    "    def __init__(self, input_dim, d_model, d_ff, num_stack, num_heads, max_length, n_iter):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_iter = n_iter\n",
    "\n",
    "        # Embeddings\n",
    "        self.obs_embed = Embedder(input_dim, d_model)\n",
    "        self.mask_embed = Embedder(input_dim, d_model)\n",
    "        self.deltas_embed = Embedder(input_dim, d_model)\n",
    "\n",
    "        # Positional Encoding\n",
    "        self.pe = PositionalEncoder_TimeDescriptor(d_model, max_length)\n",
    "\n",
    "        # Encoding blocks\n",
    "        self.obs_encoding_block = Encoding_Block(d_model, max_length, num_heads, d_ff, num_stack)\n",
    "        self.mask_encoding_block = Encoding_Block(d_model, max_length, num_heads, d_ff, num_stack)\n",
    "        self.deltas_encoding_block = Encoding_Block(d_model, max_length, num_heads, d_ff, num_stack)\n",
    "        self.comb_encoding_block = Encoding_Block(d_model, max_length, num_heads, d_ff, num_stack)\n",
    "        self.missing_comb_encoding_block = Encoding_Block(d_model, max_length, num_heads, d_ff, num_stack)\n",
    "\n",
    "        # Decoder\n",
    "        obs_embed_weight = self.obs_embed.embed.weight\n",
    "        n, v = obs_embed_weight.size()\n",
    "        self.decoder = nn.Linear(n, v, bias=False)\n",
    "        self.decoder.weight.data = obs_embed_weight.transpose(1, 0)\n",
    "        self.decoder_bias = nn.Parameter(torch.zeros(v))\n",
    "\n",
    "        # Classification layers\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(d_model * 2, d_model),\n",
    "            nn.BatchNorm1d(d_model),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(d_model, 1),\n",
    "        )\n",
    "\n",
    "        # Initialize parameters\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for weight in self.parameters():\n",
    "            if len(weight.size()) == 1:\n",
    "                continue\n",
    "            stv = 1. / math.sqrt(weight.size(1))\n",
    "            nn.init.uniform_(weight, -stv, stv)\n",
    "\n",
    "        \n",
    "    def forward(self, data, mask, times, deltas, attn_mask):\n",
    "        batch_size, seq_len, var_num = data.size()\n",
    "\n",
    "        # Input embeddings\n",
    "        x_z = self.obs_embed(data)\n",
    "        m = self.mask_embed(mask)\n",
    "        d = self.deltas_embed(deltas)\n",
    "\n",
    "        # Positional encoding\n",
    "        x_z, m, d = self.pe(x_z, m, d, times)  # Remove seq_len since it's not needed here\n",
    "\n",
    "        # Proceed with encoding blocks\n",
    "        x_z = self.obs_encoding_block(x_z, x_z, attn_mask)\n",
    "        m = self.mask_encoding_block(m, m, attn_mask)\n",
    "        d = self.deltas_encoding_block(d, d, attn_mask)\n",
    "        missing_comb_z = self.missing_comb_encoding_block(d, m, attn_mask)\n",
    "\n",
    "        # Attention distillation\n",
    "        for n in range(self.n_iter):\n",
    "            comb_z = self.comb_encoding_block(missing_comb_z, x_z, attn_mask)\n",
    "            x_z = self.obs_encoding_block(comb_z, x_z, attn_mask)\n",
    "            missing_comb_z = self.missing_comb_encoding_block(missing_comb_z, missing_comb_z, attn_mask)\n",
    "\n",
    "        # Imputation\n",
    "        x_final = x_z + missing_comb_z\n",
    "        x_dd = self.decoder(x_final) + self.decoder_bias  # Imputed output\n",
    "\n",
    "        # Classification\n",
    "        x_avg = x_z.mean(dim=1)\n",
    "        m_avg = missing_comb_z.mean(dim=1)\n",
    "        x_m_cat = torch.cat((x_avg, m_avg), dim=1)\n",
    "        out = self.classifier(x_m_cat)\n",
    "        y = torch.sigmoid(out).squeeze(-1)\n",
    "\n",
    "        return y, x_dd  # Returning both classifier output and imputed data\n",
    "\n",
    "\n",
    "class Encoding_Block(nn.Module):\n",
    "    def __init__(self, d_model, max_length, num_heads, d_ff, num_stack):\n",
    "        super().__init__()\n",
    "\n",
    "        self.N = num_stack\n",
    "\n",
    "        self.layers = get_clones(EncoderLayer(d_model, max_length, num_heads, d_ff), num_stack)\n",
    "        self.norm = Norm(d_model)\n",
    "\n",
    "    def forward(self, q, k, attn_mask):\n",
    "        # MHA Encoding\n",
    "        for i in range(self.N):\n",
    "            q, k = self.layers[i](q, k, attn_mask)\n",
    "\n",
    "        # Normalize\n",
    "        encoded_data = self.norm(q)\n",
    "        return encoded_data\n",
    "\n",
    "class Embedder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model):\n",
    "        super().__init__()\n",
    "        # self.embed = nn.Embedding(vocab_size, d_model)\n",
    "        self.embed = nn.Linear(vocab_size, d_model)\n",
    "        # self.embed = nn.Sequential(\n",
    "        #     nn.Linear(vocab_size, 32),\n",
    "        #     # nn.BatchNorm1d(128),\n",
    "        #     nn.LeakyReLU(),\n",
    "        #     nn.Linear(32, d_model),\n",
    "        # )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embed(x)\n",
    "\n",
    "class PositionalEncoder_TimeDescriptor(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_len):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "    def get_sinusoid_encoding_table(self, seq_len, d_model):\n",
    "        def cal_angle(position, hid_idx):\n",
    "            return position / np.power(self.max_seq_len, 2 * (hid_idx // 2) / d_model)\n",
    "\n",
    "        def get_posi_angle_vec(position):\n",
    "            return [cal_angle(position, hid_j) for hid_j in range(d_model)]\n",
    "\n",
    "        sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in range(seq_len)])\n",
    "\n",
    "        # Apply sin to even indices, cos to odd indices\n",
    "        sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])  # dim 2i\n",
    "        sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])  # dim 2i+1\n",
    "        return torch.FloatTensor(sinusoid_table)\n",
    "\n",
    "    def time_encoding(self, t, seq_len):\n",
    "        batch_size = t.size(0)\n",
    "        pe = self.get_sinusoid_encoding_table(seq_len, self.d_model)\n",
    "        pe = pe.unsqueeze(0).expand(batch_size, -1, -1)  # Expand to shape [batch_size, seq_len, d_model]\n",
    "        return pe\n",
    "\n",
    "    def forward(self, x, m, delta, t):\n",
    "        x = x * math.sqrt(self.d_model)\n",
    "        m = m * math.sqrt(self.d_model)\n",
    "        delta = delta * math.sqrt(self.d_model)\n",
    "\n",
    "        seq_len = x.size(1)  # Get sequence length\n",
    "        pos = self.time_encoding(t, seq_len)  # Pass t and seq_len\n",
    "\n",
    "        # Ensure pos is moved to the same device as x\n",
    "        pos = pos.to(x.device)  # Move pos to the same device as x (e.g., GPU if x is on GPU)\n",
    "\n",
    "        # Apply position encoding to x, m, delta\n",
    "        x = x + Variable(pos, requires_grad=False)\n",
    "        m = m + Variable(pos, requires_grad=False)\n",
    "        delta = delta + Variable(pos, requires_grad=False)\n",
    "\n",
    "        return x, m, delta\n",
    "\n",
    "    \n",
    "\n",
    "def get_clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])\n",
    "\n",
    "class Norm(nn.Module):\n",
    "    def __init__(self, d_model, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.size = d_model\n",
    "\n",
    "        # create two learnable parameters to calibrate normalisation\n",
    "        self.alpha = nn.Parameter(torch.ones(self.size))\n",
    "        self.bias = nn.Parameter(torch.zeros(self.size))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        norm = self.alpha * (x - x.mean(dim=-1, keepdim=True)) \\\n",
    "               / (x.std(dim=-1, keepdim=True) + self.eps) + self.bias\n",
    "        return norm\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, heads, d_model, dropout=0.2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_k = d_model // heads\n",
    "        self.h = heads\n",
    "\n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.out = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, q, k, v, tp, mask=None):\n",
    "        bs = q.size(0)\n",
    "\n",
    "        # perform linear operation and split into h heads\n",
    "        k = self.k_linear(k).view(bs, -1, self.h, self.d_k)  # [batch_size * len_q * n_heads * hidden_dim]\n",
    "        q = self.q_linear(q).view(bs, -1, self.h, self.d_k)  # [batch_size * len_q * n_heads * hidden_dim]\n",
    "        v = self.v_linear(v).view(bs, -1, self.h, self.d_k)  # [batch_size * len_q * n_heads * hidden_dim]\n",
    "\n",
    "        # transpose to get dimensions bs * h * sl * d_model\n",
    "        k = k.transpose(1, 2)  # [batch_size * n_heads * len_q * hidden_dim]\n",
    "        q = q.transpose(1, 2)  # [batch_size * n_heads * len_q * hidden_dim]\n",
    "        v = v.transpose(1, 2)  # [batch_size * n_heads * len_q * hidden_dim]\n",
    "\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1).repeat(1, self.h, 1, 1)  # [batch_size x n_heads x len_q x len_k]\n",
    "\n",
    "\n",
    "        if tp == 1:  # if transpose\n",
    "            k = k.transpose(2, 3)  # [batch_size * n_heads * hidden_dim * len_q]\n",
    "            q = q.transpose(2, 3)  # [batch_size * n_heads * hidden_dim * len_q]\n",
    "            v = v.transpose(2, 3)  # [batch_size * n_heads * hidden_dim * len_q]\n",
    "\n",
    "\n",
    "        # calculate attention using function we will define next\n",
    "        scores = attention(q, k, v, self.d_k, mask, self.dropout)\n",
    "        if tf == 1:\n",
    "            scores = scores.transpose(2, 3)\n",
    "\n",
    "        # concatenate heads and put through final linear layer\n",
    "        concat = scores.transpose(1, 2).contiguous() \\\n",
    "            .view(bs, -1, self.d_model)\n",
    "\n",
    "        output = self.out(concat)\n",
    "\n",
    "        return output\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        # We set d_ff as a default to 2048\n",
    "        self.linear_1 = nn.Linear(d_model, d_ff)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear_2 = nn.Linear(d_ff, d_model)\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(F.relu(self.linear_1(x)))\n",
    "        x = self.linear_2(x)\n",
    "        return x\n",
    "\n",
    "def attention(q, k, v, d_k, mask=None, dropout=None):\n",
    "    \"\"\"\n",
    "    :param q: Batch x n_head x max_seq_len x variable\n",
    "    :param k: Batch x n_head x max_seq_len x variable\n",
    "    :param v: Batch x n_head x max_seq_len x variable\n",
    "    :param d_k:\n",
    "    :param mask: Batch x n_had x max_seq_len x max_seq_len\n",
    "    :param dropout:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k)  # [Batch x n_head x max_seq_len x max_seq_len]\n",
    "\n",
    "    # Attention calculation 전에 attn_mask를 Boolean으로 변환합니다\n",
    "    if mask is not None:\n",
    "        mask = mask.bool()  # Ensure mask is boolean\n",
    "        scores = scores.masked_fill(mask, -1e9)\n",
    "    scores = F.softmax(scores, dim=-1)\n",
    "\n",
    "    if dropout is not None:\n",
    "        scores = dropout(scores)\n",
    "\n",
    "    output = torch.matmul(scores, v)\n",
    "    return output\n",
    "\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, max_length, heads, d_ff, dropout=0):\n",
    "        super().__init__()\n",
    "        self.norm_q = Norm(d_model)\n",
    "        self.norm_k = Norm(d_model)\n",
    "        self.norm_q_attn = Norm(d_model)\n",
    "\n",
    "        self.attn = MultiHeadAttention(heads, d_model)\n",
    "        self.time_attn = MultiHeadAttention(heads, d_model)\n",
    "        self.var_attn = MultiHeadAttention(heads, d_model)\n",
    "\n",
    "        self.ff = FeedForward(d_model, d_ff)\n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "        self.dropout_2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.cat_lin = nn.Linear(128, 64)\n",
    "\n",
    "    def forward(self, q, k, mask):\n",
    "        q2 = self.norm_q(q)\n",
    "        k2 = self.norm_k(k)\n",
    "        q = q + self.dropout_1(self.attn(q2, k2, k2, 0, mask))\n",
    "        q2 = self.norm_q_attn(q)\n",
    "        q = q + self.dropout_2(self.ff(q2))\n",
    "\n",
    "        return q, k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41cd496-6bf6-4464-9c9c-79187df9935f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70d06252-b32e-49e8-bfec-292100c4efea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self,  lambda1, device, alpha=1, gamma=0, logits=False, reduce=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.logits = logits\n",
    "        self.reduce = reduce\n",
    "        self.device = device\n",
    "        self.lambda1 = torch.tensor(lambda1).to(device)\n",
    "\n",
    "    def forward(self, model, inputs, targets):\n",
    "        if self.logits:\n",
    "            BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
    "        else:\n",
    "            BCE_loss = F.binary_cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-1*BCE_loss)\n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "\n",
    "        # Regularization\n",
    "        l1_regularization = torch.tensor(0).float().to(self.device)\n",
    "        for param in model.parameters():\n",
    "            l1_regularization += torch.norm(param.to(self.device), 1)\n",
    "\n",
    "        # Take the average\n",
    "        loss = torch.mean(F_loss) + (self.lambda1 * l1_regularization)\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "class WeightedBCE(nn.Module):\n",
    "    def __init__(self,  device):\n",
    "        super(WeightedBCE, self).__init__()\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, model, inputs, targets):\n",
    "        inputs = inputs.detach().cpu()\n",
    "        targets = targets.detach().cpu()\n",
    "\n",
    "        pos_num = len(np.where(targets == 1)[0])\n",
    "        neg_num = len(np.where(targets == 0)[0])\n",
    "        if pos_num == 0:\n",
    "            pos_weight = 1.0\n",
    "        else:\n",
    "            pos_weight = neg_num / pos_num\n",
    "        weights = torch.zeros(len(targets))\n",
    "\n",
    "        for i in range(len(targets)):\n",
    "            if i == 1:\n",
    "                weights[i] = pos_weight\n",
    "            else:\n",
    "                weights[i] = 1.0\n",
    "\n",
    "        loss = F.binary_cross_entropy_with_logits(inputs, targets, pos_weight=weights)\n",
    "\n",
    "        return loss.to(self.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8606e00-6962-4f0b-8571-ed01b0f4c1b4",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd276017-be12-411a-8880-aa0690f61de6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.optim.optimizer import Optimizer\n",
    "\n",
    "class RAdam(Optimizer):\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0):\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
    "        self.buffer = [[None, None, None] for ind in range(10)]\n",
    "        super(RAdam, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(RAdam, self).__setstate__(state)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data.float()\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError('RAdam does not support sparse gradients')\n",
    "\n",
    "                p_data_fp32 = p.data.float()\n",
    "\n",
    "                state = self.state[p]\n",
    "\n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n",
    "                else:\n",
    "                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n",
    "\n",
    "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
    "                beta1, beta2 = group['betas']\n",
    "\n",
    "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
    "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
    "\n",
    "                state['step'] += 1\n",
    "                buffered = self.buffer[int(state['step'] % 10)]\n",
    "                if state['step'] == buffered[0]:\n",
    "                    N_sma, step_size = buffered[1], buffered[2]\n",
    "                else:\n",
    "                    buffered[0] = state['step']\n",
    "                    beta2_t = beta2 ** state['step']\n",
    "                    N_sma_max = 2 / (1 - beta2) - 1\n",
    "                    N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n",
    "                    buffered[1] = N_sma\n",
    "\n",
    "                    # more conservative since it's an approximated value\n",
    "                    if N_sma >= 5:\n",
    "                        step_size = math.sqrt(\n",
    "                            (1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (\n",
    "                                        N_sma_max - 2)) / (1 - beta1 ** state['step'])\n",
    "                    else:\n",
    "                        step_size = 1.0 / (1 - beta1 ** state['step'])\n",
    "                    buffered[2] = step_size\n",
    "\n",
    "                if group['weight_decay'] != 0:\n",
    "                    p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n",
    "\n",
    "                # more conservative since it's an approximated value\n",
    "                if N_sma >= 5:\n",
    "                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
    "                    p_data_fp32.addcdiv_(-step_size * group['lr'], exp_avg, denom)\n",
    "                else:\n",
    "                    p_data_fp32.add_(-step_size * group['lr'], exp_avg)\n",
    "\n",
    "                p.data.copy_(p_data_fp32)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "54cab25c-0301-4b6b-ae6a-d25d5e4a2fac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "9f5be4af-ca1e-42a6-bbff-9f5f693492d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "6515386a-da77-44c4-9e56-b3157389ab22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0647a6-0e60-4b61-a239-4f8639cb2e73",
   "metadata": {},
   "source": [
    "## Train & Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "992ae9b0-bfdb-4bdd-befe-efbad92796ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "# Seed\n",
    "manualSeed = 64\n",
    "np.random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.cuda.manual_seed(manualSeed)\n",
    "torch.cuda.manual_seed_all(manualSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "6b3c09b1-9cc3-4f58-9a09-d93537eb31a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate_fn(recs):\n",
    "    rec_dict = {'values': torch.FloatTensor(np.array([r['values'] for r in recs])),\n",
    "                'masks': torch.FloatTensor(np.array([r['masks'] for r in recs])),\n",
    "                'deltas': torch.FloatTensor(np.array([r['deltas'] for r in recs])),\n",
    "                'times': torch.FloatTensor(np.array([r['times'] for r in recs])),\n",
    "                'labels': torch.FloatTensor(np.array([r['labels'] for r in recs]))\n",
    "                }\n",
    "    return rec_dict\n",
    "\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_fns(recs):\n",
    "    # Pad values, masks, deltas, and times using pad_sequence\n",
    "    values = [r['values'] for r in recs]\n",
    "    masks = [r['masks'] for r in recs]\n",
    "    deltas = [r['deltas'] for r in recs]\n",
    "    times = [r['times'] for r in recs]\n",
    "    \n",
    "    # Apply padding for variable length sequences\n",
    "    values_padded = pad_sequence(values, batch_first=True)\n",
    "    masks_padded = pad_sequence(masks, batch_first=True)\n",
    "    deltas_padded = pad_sequence(deltas, batch_first=True)\n",
    "    times_padded = pad_sequence(times, batch_first=True)\n",
    "    \n",
    "    # Convert the labels (In-hospital death and LOS) to tensors directly (no padding needed)\n",
    "    labels = torch.FloatTensor([r['labels'] for r in recs])\n",
    "    #labels = torch.FloatTensor([r['labels'] for r in recs]).squeeze(-1)\n",
    "    los_labels = torch.FloatTensor([r['los_labels'] for r in recs])#.squeeze(-1)\n",
    "    \n",
    "    rec_dict = {\n",
    "        'values': values_padded,\n",
    "        'masks': masks_padded,\n",
    "        'deltas': deltas_padded,\n",
    "        'times': times_padded,\n",
    "        'labels': labels,\n",
    "        'los_labels': los_labels\n",
    "    }\n",
    "    return rec_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "e97aa15f-eb71-424e-9f29-44ac379da7a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dataloader(data_labeled, batch_size):\n",
    "    data_list = []\n",
    "\n",
    "    for _, (df, outcome) in data_labeled.items():\n",
    "        values = torch.tensor(df.values, dtype=torch.float32)\n",
    "        \n",
    "        # Generate mask for observed (1) and missing (0) values\n",
    "        mask = ~torch.isnan(values)\n",
    "        mask = mask.float()\n",
    "\n",
    "        # Replace NaNs in values with zero for processing\n",
    "        values = torch.nan_to_num(values, nan=0.0)\n",
    "\n",
    "        # Calculate absolute time steps and deltas\n",
    "        times = torch.arange(values.size(0)).unsqueeze(-1).repeat(1, values.size(1))\n",
    "        deltas = torch.zeros_like(times, dtype=torch.float32)\n",
    "        for t in range(1, times.size(0)):\n",
    "            for d in range(values.size(1)):\n",
    "                if mask[t-1, d] == 0:\n",
    "                    deltas[t, d] = deltas[t-1, d] + (times[t, d] - times[t-1, d])\n",
    "                else:\n",
    "                    deltas[t, d] = times[t, d] - times[t-1, d]\n",
    "\n",
    "        label = outcome[['In-hospital_death']].values[0]\n",
    "        los_label = outcome[['Length_of_stay']].values[0]\n",
    "\n",
    "        # Append all values to the list\n",
    "        data_list.append({'values': values, 'masks': mask, 'times': times, 'deltas': deltas, 'labels': label, 'los_labels': los_label})\n",
    "\n",
    "    # Create the DataLoader with the updated collate function\n",
    "    dataset = data_list\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=True, pin_memory=True, collate_fn=collate_fns)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "102973d7-7568-4489-9956-2897efe23a38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyperparameters and initialization\n",
    "input_dim = 35  # Number of time-series variables\n",
    "d_model = 64  # Embedding dimension\n",
    "d_ff = 128  # Feedforward dimension\n",
    "num_stack = 2 # Number of encoder layers\n",
    "num_heads = 8  # Number of attention heads\n",
    "max_length = 215  # Maximum sequence length\n",
    "n_iter = 3  # Number of distillation iterations\n",
    "num_epochs = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "05237068-6707-436d-ae41-1f40fd8fae09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alpha = 9\n",
    "# gamma = 0.1\n",
    "# # Loss rates\n",
    "# beta = 0.1\n",
    "# delta = 11\n",
    "\n",
    "gamma = 0.15\n",
    "# Loss rates\n",
    "lambda_1 = 0\n",
    "lambda_2 = 1\n",
    "lambda_3 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "4a97cb54-e381-4e93-9e69-a9d10f066488",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lambda1 = 5e-4\n",
    "learning_rate = 5e-4\n",
    "lr_decay = 10\n",
    "lr_ratio = 0.2\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "6b60cb9f-8e98-41b9-baf7-ac23dfca17d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, verbose=1):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.best_auc = None\n",
    "        self.counter = 0\n",
    "\n",
    "    def step(self, current_auc):\n",
    "        if self.best_auc is None:\n",
    "            self.best_auc = current_auc\n",
    "            return False  # Not yet stopped\n",
    "        elif current_auc > self.best_auc:\n",
    "            self.best_auc = current_auc\n",
    "            self.counter = 0  # Reset counter\n",
    "            return False  # Not stopped\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                if self.verbose:\n",
    "                    print(\"Early stopping activated!\")\n",
    "                return True  # Stop training\n",
    "            return False  # Not stopped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "db0dc36e-06a6-4fc9-9467-59fa29d957fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_validate(train_loader, valid_loader, input_dim, d_model, d_ff, num_stack, num_heads, max_length, n_iter, num_epochs, device, lambda_1, lambda_2, lambda_3, gamma, alpha, lr_decay, lr_ratio, batch_size):\n",
    "    # Initialize model and optimizer\n",
    "    model = Multi_Duration_Pipeline_Residual(input_dim, d_model, d_ff, num_stack, num_heads, max_length, n_iter).to(device)\n",
    "\n",
    "    optimizer = torch.optim.RAdam(model.parameters(), lr=0.005)\n",
    "    criterion_focal = FocalLoss(lambda1=1.0, device=device, gamma=gamma, alpha=alpha, logits=False).to(device)\n",
    "    criterion_mse = nn.MSELoss()\n",
    "    scheduler = StepLR(optimizer, step_size=lr_decay, gamma=lr_ratio)\n",
    "    \n",
    "    best_valid_auc = 0  # Track best validation AUC\n",
    "    early_stopping = EarlyStopping(patience=20)  # Early stopping initialization\n",
    "    \n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        train_loss = 0\n",
    "        n_batches = 0\n",
    "        \n",
    "        # Training loop\n",
    "        for batch_idx, data in enumerate(train_loader):\n",
    "            x = data['values'].to(device)  # Batch x Time x Variable\n",
    "            m = data['masks'].to(device)  # Batch x Time x Variable\n",
    "            deltas = data['deltas'].to(device)  # Batch x Time x Variable\n",
    "            times = data['times'].to(device)  # Batch x Time x Variable\n",
    "            y = data['labels'].to(device)  # In-hospital death\n",
    "            y1 = data['los_labels'].to(device)  # Length of stay\n",
    "            \n",
    "            # Zero Grad\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Create attention mask (assuming mask is based on deltas)\n",
    "            attn_mask = deltas.data.eq(0)[:, :, 0]\n",
    "            attn_mask[:, 0] = 0\n",
    "            \n",
    "            # Forward pass through the model\n",
    "            los_out, y_hat, out = model(x, m, times, deltas, attn_mask)\n",
    "            \n",
    "            # Ensure correct shapes for loss calculation\n",
    "            y1_target = y1 if y1.dim() == 2 else y1.unsqueeze(-1)  # Ensure y1 is 2D\n",
    "            y_target = y if y.dim() == 2 else y.unsqueeze(-1)  # Ensure y is 2D\n",
    "            \n",
    "            # Loss calculation\n",
    "            # Ensure y_hat and y_target have the same shape\n",
    "            if y_hat.shape != y_target.shape:\n",
    "                y_target = y_target.view_as(y_hat)\n",
    "\n",
    "            \n",
    "            loss_los = criterion_mse(los_out, y1_target[:, -1])  # Length of stay loss\n",
    "            loss_cls = criterion_focal(model, y_hat, y_target[:, -1])  # In-hospital death loss\n",
    "            loss_imp = criterion_mse(out, x)  # Imputation loss\n",
    "            \n",
    "            # Total loss\n",
    "            loss = lambda_1 * loss_cls + lambda_2 * loss_los + lambda_3 * loss_imp\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            n_batches += 1\n",
    "\n",
    "        train_loss /= n_batches\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Training Loss: {train_loss:.4f}\")\n",
    "\n",
    "        # Validation process\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        valid_loss = 0\n",
    "        valid_labels = []\n",
    "        valid_predictions = []\n",
    "        valid_los_predictions = []\n",
    "        valid_los_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in valid_loader:\n",
    "                x = batch['values'].to(device)\n",
    "                m = batch['masks'].to(device)\n",
    "                deltas = batch['deltas'].to(device)\n",
    "                times = batch['times'].to(device)\n",
    "                y = batch['labels'].to(device)\n",
    "                y1 = batch['los_labels'].to(device)\n",
    "                \n",
    "                attn_mask = deltas.data.eq(0)[:, :, 0]\n",
    "                attn_mask[:, 0] = 0\n",
    "                \n",
    "                los_out, y_hat, out = model(x, m, times, deltas, attn_mask)\n",
    "\n",
    "                # Ensure correct shapes for loss calculation\n",
    "                y1_target = y1 if y1.dim() == 2 else y1.unsqueeze(-1)  # Ensure y1 is 2D\n",
    "                y_target = y if y.dim() == 2 else y.unsqueeze(-1)  # Ensure y is 2D\n",
    "\n",
    "                # Loss calculation\n",
    "                loss_los = criterion_mse(los_out, y1_target[:, -1])  # Length of stay loss\n",
    "                if y_hat.shape != y_target.shape:\n",
    "                    y_target = y_target.view_as(y_hat)\n",
    "                loss_cls = criterion_focal(model, y_hat, y_target[:, -1])  # In-hospital death loss\n",
    "                loss_imp = criterion_mse(out, x)  # Imputation loss\n",
    "\n",
    "                valid_loss += (lambda_1 * loss_cls + lambda_2 * loss_los + lambda_3 * loss_imp).item()\n",
    "\n",
    "                # Collect labels and predictions\n",
    "                valid_labels.append(y.cpu().numpy())\n",
    "                valid_predictions.append(y_hat.cpu().numpy())\n",
    "                valid_los_labels.append(y1.cpu().numpy())\n",
    "                valid_los_predictions.append(los_out.cpu().numpy())\n",
    "                \n",
    "        valid_loss /= len(valid_loader)\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Validation Loss: {valid_loss:.4f}\")\n",
    "        \n",
    "        # Early stopping logic\n",
    "        # Add early stopping based on validation AUC or loss as per your implementation\n",
    "        \n",
    "        scheduler.step()  # Update learning rate\n",
    "    \n",
    "    print(\"Training and validation complete.\")\n",
    "\n",
    "\n",
    "# Convert to DataLoader\n",
    "train_loader = create_dataloader(data_a_labeled, batch_size)\n",
    "valid_loader = create_dataloader(data_b_labeled, batch_size)\n",
    "    \n",
    "# Assuming data loaders are initialized\n",
    "train_and_validate(train_loader, valid_loader, input_dim, d_model, d_ff, num_stack, num_heads, max_length, n_iter, num_epochs, device, lambda_1, lambda_2, lambda_3, gamma, alpha, lr_decay, lr_ratio, batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8289f78a-025d-4975-ad32-498ab154a890",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e83abc1-149b-49c8-9ff2-d7fe86bb9b56",
   "metadata": {},
   "source": [
    "The model part is taken from the authors' code, but the performance is different from the performance described in the paper.\n",
    "\n",
    "There are several reasons for the discrepancy, such as the absence of benchmark parameters in the author's published code and the fact that the actual downloaded data differs from the description in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "f2c5da91-b9fc-4adf-aaab-04fb7008abc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585615c0-8b5f-4f8b-b48d-ce460ba5c069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5539ab-c928-4754-bf1b-84abda405445",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "miam",
   "language": "python",
   "name": "miam"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
