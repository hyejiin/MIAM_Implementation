{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f47941c-3051-44ef-a528-2f1091461ac2",
   "metadata": {},
   "source": [
    "###  PyTorch implementation of the paper : Multi-view Integration Learning for Irregularly-sampled Clinical Time Series (MIAM) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276584f8-e2a1-4b7c-854b-8fab6f0c6574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_curve, roc_auc_score\n",
    "\n",
    "import tensorflow as tf\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "from attention_graph_util import *\n",
    "import copy\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_recall_curve\n",
    "from sklearn.model_selection import KFold\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f602cfec-b747-4bdd-b8d5-33275aaf5382",
   "metadata": {},
   "source": [
    "### Data Preprocessing and Transformation to MIAM Format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16eb6577-5572-4778-b1d5-0df0fccfe8f0",
   "metadata": {},
   "source": [
    "Using PhysioNet 2012 Challenge dataset, In-Hospital Mortality Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7c3ef393-d201-415a-9010-2e2e1615ef70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define data folders and outcomes paths for each set\n",
    "data_folder_a = \"/media/usr/HDD/Data/EHR/Challenge_2012/set-a\"\n",
    "data_folder_b = \"/media/usr/HDD/Data/EHR/Challenge_2012/set-b\"\n",
    "data_folder_c = \"/media/usr/HDD/Data/EHR/Challenge_2012/set-c\"\n",
    "outcomes_path_a = \"/media/usr/HDD/Data/EHR/Challenge_2012/Outcomes-a.txt\"\n",
    "outcomes_path_b = \"/media/usr/HDD/Data/EHR/Challenge_2012/Outcomes-b.txt\"\n",
    "outcomes_path_c = \"/media/usr/HDD/Data/EHR/Challenge_2012/Outcomes-c.txt\"\n",
    "\n",
    "def load_txt_data(folder_path):\n",
    "    data_dict = {}\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.txt'):\n",
    "            record_id = file_name.split('.')[0]\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            df = pd.read_csv(file_path, sep=',')\n",
    "            data_dict[record_id] = df\n",
    "    return data_dict\n",
    "\n",
    "def load_outcomes(outcomes_path):\n",
    "    outcomes_df = pd.read_csv(outcomes_path, sep=',')\n",
    "    outcomes_df.set_index('RecordID', inplace=True)\n",
    "    return outcomes_df\n",
    "\n",
    "\n",
    "\n",
    "from scipy.stats.mstats import winsorize\n",
    "\n",
    "def apply_winsorize(data_dict):\n",
    "    for record_id, df in data_dict.items():\n",
    "        for column in df.columns:\n",
    "            # 열이 비어 있지 않은지 확인\n",
    "            if df[column].notna().sum() > 0:\n",
    "                df[column] = winsorize(df[column], limits=[0.02, 0.02])\n",
    "    return data_dict\n",
    "\n",
    "\n",
    "def z_normalize(data_dict, mean_dict=None, std_dict=None, is_train=True):\n",
    "    if is_train:\n",
    "        mean_dict = {}\n",
    "        std_dict = {}\n",
    "        for record_id, df in data_dict.items():\n",
    "            for column in df.columns:\n",
    "                if column not in mean_dict:\n",
    "                    mean_dict[column] = df[column].mean()\n",
    "                    std_dict[column] = df[column].std()\n",
    "\n",
    "    for record_id, df in data_dict.items():\n",
    "        for column in df.columns:\n",
    "            if std_dict[column] != 0:\n",
    "                df[column] = (df[column] - mean_dict[column]) / std_dict[column]\n",
    "    \n",
    "    return data_dict, mean_dict, std_dict\n",
    "\n",
    "\n",
    "\n",
    "# def preprocess_data_with_fixed_variables(data_dict, variable_list):\n",
    "#     processed_data = {}\n",
    "#     for record_id, df in data_dict.items():\n",
    "#         df = df.groupby(['Time', 'Parameter'], as_index=False).mean()\n",
    "#         df_pivot = df.pivot(index='Time', columns='Parameter', values='Value')\n",
    "#         df_pivot = df_pivot.reindex(columns=variable_list, fill_value=np.nan)\n",
    "#         processed_data[record_id] = df_pivot.reset_index(drop=True)\n",
    "#     return processed_data\n",
    "\n",
    "variable_list = [\n",
    "    'DiasABP', 'NIDiasABP', 'FiO2', 'GCS',\n",
    "'HR', 'MAP', 'NIMAP', 'PaCO2', 'PaO2',\n",
    "'RespRate', 'SysABP', 'NISysABP', 'Temp', 'Urine',\n",
    "'ALP', 'ALT', 'AST', 'Albumin',\n",
    "'BUN', 'Bilirubin', 'Cholesterol', 'Creatinine', 'Glucose', 'HCO3', 'HCT',\n",
    "'K', 'Lactate', 'Mg', 'Na', 'Platelets',\n",
    "'SaO2', 'TropI', 'TropT', 'WBC', 'pH']\n",
    "\n",
    "\n",
    "def preprocess_data_with_fixed_variables(data_dict, variable_list):\n",
    "    processed_data = {}\n",
    "    for record_id, df in data_dict.items():\n",
    "        # 'RecordID', 'Age', 'Gender', 'Height', 'ICUType' 등 일반 정보 제외\n",
    "        df = df[~df['Parameter'].isin(['RecordID', 'Age', 'Gender', 'Height', 'ICUType', 'Weight'])]\n",
    "        \n",
    "        # 'Time'과 'Parameter'로 groupby 후 평균을 계산해 중복 해결\n",
    "        df = df.groupby(['Time', 'Parameter'], as_index=False).mean()\n",
    "\n",
    "        # 피벗 테이블을 만들어 변수들을 열로 변환\n",
    "        df_pivot = df.pivot(index='Time', columns='Parameter', values='Value')\n",
    "\n",
    "        # 변수 리스트에 맞춰 열을 정렬하고, 누락된 변수는 NaN으로 채움\n",
    "        df_pivot = df_pivot.reindex(columns=variable_list, fill_value=np.nan)\n",
    "\n",
    "        # 처리된 데이터를 사전에 저장\n",
    "        processed_data[record_id] = df_pivot.reset_index(drop=True)\n",
    "    \n",
    "    return processed_data\n",
    "\n",
    "\n",
    "\n",
    "def map_outcomes(data_dict, outcomes_df):\n",
    "    labeled_data = {}\n",
    "    for record_id, df in data_dict.items():\n",
    "        if int(record_id) in outcomes_df.index:\n",
    "            outcome = outcomes_df.loc[int(record_id)]\n",
    "            labeled_data[record_id] = (df, outcome)\n",
    "    return labeled_data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "cf44e0cc-752d-48d7-a4aa-2b1a23ae1de3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Assuming all previous functions and model definitions are included\n",
    "\n",
    "# Load data for each set\n",
    "data_a = load_txt_data(data_folder_a)\n",
    "data_b = load_txt_data(data_folder_b)\n",
    "data_c = load_txt_data(data_folder_c)\n",
    "\n",
    "# Load outcomes for each set\n",
    "outcomes_a = load_outcomes(outcomes_path_a)\n",
    "outcomes_b = load_outcomes(outcomes_path_b)\n",
    "outcomes_c = load_outcomes(outcomes_path_c)\n",
    "\n",
    "data_a = preprocess_data_with_fixed_variables(data_a, variable_list)\n",
    "data_b = preprocess_data_with_fixed_variables(data_b, variable_list)\n",
    "data_c = preprocess_data_with_fixed_variables(data_c, variable_list)\n",
    "\n",
    "# Preprocess the data\n",
    "data_a = apply_winsorize(data_a)\n",
    "data_a, mean_dict, std_dict = z_normalize(data_a, is_train=True)\n",
    "data_b = apply_winsorize(data_b)\n",
    "data_b, _, _ = z_normalize(data_b, mean_dict, std_dict, is_train=False)\n",
    "data_c = apply_winsorize(data_c)\n",
    "data_c, _, _ = z_normalize(data_c, mean_dict, std_dict, is_train=False)\n",
    "\n",
    "\n",
    "\n",
    "# data_a = zero_imputation(data_a)\n",
    "# data_b = zero_imputation(data_b)\n",
    "# data_c = zero_imputation(data_c)\n",
    "\n",
    "data_a_labeled = map_outcomes(data_a, outcomes_a)\n",
    "data_b_labeled = map_outcomes(data_b, outcomes_b)\n",
    "data_c_labeled = map_outcomes(data_c, outcomes_c)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "b9318b17-3d63-4ff9-b0ae-0f6dfa79df05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patients in filtered data_a: 1416\n",
      "Number of patients in filtered data_b: 1411\n",
      "Number of patients in filtered data_c: 1424\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of patients in filtered data_a:\", len(data_a_labeled))\n",
    "print(\"Number of patients in filtered data_b:\", len(data_b_labeled))\n",
    "print(\"Number of patients in filtered data_c:\", len(data_c_labeled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "bacb853f-d890-45d1-8d89-bccc44ca66e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum time-series length in data_a: 202\n",
      "Maximum time-series length in data_b: 185\n",
      "Maximum time-series length in data_c: 214\n"
     ]
    }
   ],
   "source": [
    "# Function to find the maximum time-series length in a dataset\n",
    "def get_max_time_series_length(data_set):\n",
    "    max_length = max(patient_data[0].shape[0] for patient_data in data_set.values())  # patient_data[0] is the DataFrame\n",
    "    return max_length\n",
    "\n",
    "# Calculate and print the maximum time-series length for each dataset\n",
    "max_length_a = get_max_time_series_length(data_a_labeled)\n",
    "max_length_b = get_max_time_series_length(data_b_labeled)\n",
    "max_length_c = get_max_time_series_length(data_c_labeled)\n",
    "\n",
    "print(\"Maximum time-series length in data_a:\", max_length_a)\n",
    "print(\"Maximum time-series length in data_b:\", max_length_b)\n",
    "print(\"Maximum time-series length in data_c:\", max_length_c)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "b4491a98-672a-45e5-b058-524786635df9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(616, 3635, 5.900974025974026)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure that outcomes_a.index is a string\n",
    "outcomes_a.index = outcomes_a.index.astype(str)\n",
    "outcomes_b.index = outcomes_b.index.astype(str)\n",
    "outcomes_c.index = outcomes_c.index.astype(str)\n",
    "\n",
    "# Filter outcomes based on the existing keys in filtered_data_a (which are already strings)\n",
    "filtered_outcomes_a = outcomes_a.loc[outcomes_a.index.isin(filtered_data_a.keys())]\n",
    "filtered_outcomes_b = outcomes_b.loc[outcomes_b.index.isin(filtered_data_b.keys())]\n",
    "filtered_outcomes_c = outcomes_c.loc[outcomes_c.index.isin(filtered_data_c.keys())]\n",
    "\n",
    "# Concatenate the filtered outcomes\n",
    "filtered_outcomes = pd.concat([filtered_outcomes_a, filtered_outcomes_b, filtered_outcomes_c])\n",
    "\n",
    "# Count positive and negative outcomes\n",
    "positive_count = filtered_outcomes['In-hospital_death'].sum()\n",
    "negative_count = len(filtered_outcomes) - positive_count\n",
    "\n",
    "# Calculate the imbalance ratio\n",
    "imbalance_ratio = negative_count / positive_count\n",
    "\n",
    "# Display the results\n",
    "positive_count, negative_count, imbalance_ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "8569ed25-f0b1-4bc1-a49b-ea9a4829ff2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Rate: 85.61%\n"
     ]
    }
   ],
   "source": [
    "def calculate_missing_rate(data_dict):\n",
    "    total_values = 0\n",
    "    missing_values = 0\n",
    "\n",
    "    # Loop over each record (patient) in the dataset\n",
    "    for record_id, (df, outcome) in data_dict.items():  # Access the first element in the tuple (df)\n",
    "        total_values += df.size  # Total number of values (cells) in the DataFrame\n",
    "        missing_values += df.isna().sum().sum()  # Count the NaN values as missing\n",
    "\n",
    "    missing_rate = (missing_values / total_values) * 100\n",
    "    return missing_rate\n",
    "\n",
    "# Assuming data_a_labeled is the dataset after loading and preprocessing\n",
    "missing_rate = calculate_missing_rate(data_a_labeled)\n",
    "print(f\"Missing Rate: {missing_rate:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "8908300f-153b-4fbf-b85d-1180a2c413b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(variable_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121ceb75-40b2-499a-a84e-7a1695fb2081",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Data Differences from paper \n",
    "\n",
    "- Maximum time series length: 214 (The paper says \"The number of irregular time points ranged from 1 to 202\")\n",
    "- Positive_counts, negative_counts: 616, 3635 (in paper, 554 positive, 3,443 negative)\n",
    "- Number of patients: 4251 (in paper, 3,997)\n",
    "- Missing Rate : 85.61% (in paper, 80.5%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a3051a-6c1a-4ef2-962e-ab0bb82f898b",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "eeb078c4-7890-4959-9b78-e971ec169438",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Multi_Duration_Pipeline_Residual(nn.Module):\n",
    "    def __init__(self, input_dim, d_model, d_ff, num_stack, num_heads, max_length, n_iter):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_iter = n_iter\n",
    "\n",
    "        # Embeddings\n",
    "        self.obs_embed = Embedder(input_dim, d_model)\n",
    "        self.mask_embed = Embedder(input_dim, d_model)\n",
    "        self.deltas_embed = Embedder(input_dim, d_model)\n",
    "\n",
    "        # Positional Encoding\n",
    "        self.pe = PositionalEncoder_TimeDescriptor(d_model, max_length)\n",
    "\n",
    "        # Encoding blocks\n",
    "        self.obs_encoding_block = Encoding_Block(d_model, max_length, num_heads, d_ff, num_stack)\n",
    "        self.mask_encoding_block = Encoding_Block(d_model, max_length, num_heads, d_ff, num_stack)\n",
    "        self.deltas_encoding_block = Encoding_Block(d_model, max_length, num_heads, d_ff, num_stack)\n",
    "        self.comb_encoding_block = Encoding_Block(d_model, max_length, num_heads, d_ff, num_stack)\n",
    "        self.missing_comb_encoding_block = Encoding_Block(d_model, max_length, num_heads, d_ff, num_stack)\n",
    "\n",
    "        # Decoder\n",
    "        obs_embed_weight = self.obs_embed.embed.weight\n",
    "        n, v = obs_embed_weight.size()\n",
    "        self.decoder = nn.Linear(n, v, bias=False)\n",
    "        self.decoder.weight.data = obs_embed_weight.transpose(1, 0)\n",
    "        self.decoder_bias = nn.Parameter(torch.zeros(v))\n",
    "\n",
    "\n",
    "        \n",
    "        self.los_classifier = nn.Sequential(\n",
    "            nn.Linear(d_model * 2, d_model),\n",
    "            nn.BatchNorm1d(d_model),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(d_model, 1),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(d_model * 2, d_model),\n",
    "            nn.BatchNorm1d(d_model),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(d_model, 1),\n",
    "        )\n",
    "\n",
    "        self.classifier2 = nn.Sequential(\n",
    "            nn.Linear(input_dim * 2, input_dim),\n",
    "            nn.BatchNorm1d(input_dim),\n",
    "            # nn.LeakyReLU(),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(input_dim, 1))\n",
    "\n",
    "        self.time_encoding_block = Encoding_Block(d_model, 3, num_heads, d_ff, num_stack)\n",
    "        self.reset_parameters()\n",
    "\n",
    "        self.lin_clsf = nn.Sequential(\n",
    "            nn.Linear(d_model*2, 1),\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for weight in self.parameters():\n",
    "            if len(weight.size()) == 1:\n",
    "                continue\n",
    "            stv = 1. / math.sqrt(weight.size(1))\n",
    "            nn.init.uniform_(weight, -stv, stv)\n",
    "\n",
    "        \n",
    "    def forward(self, data, mask, times, deltas, attn_mask):\n",
    "        \"\"\"\n",
    "        :param src: Batch x Max_seq_len x Variable\n",
    "        :param mask: Batch x Max_seq_len x Max_seq_len\n",
    "        \"\"\"\n",
    "\n",
    "        # make attn_mask\n",
    "        batch_size, seq_len, var_num = data.size()\n",
    "        attn_mask = attn_mask.unsqueeze(1)\n",
    "        attn_mask = attn_mask.expand(batch_size, seq_len, seq_len)\n",
    "\n",
    "        # Datas\n",
    "        d_z = data#[:, 0, :, :]\n",
    "\n",
    "        # Input embedding\n",
    "        x_z = self.obs_embed(d_z)\n",
    "        m = self.mask_embed(mask)\n",
    "        d = self.deltas_embed(deltas)\n",
    "\n",
    "        # Positional encoding\n",
    "        x_z, m, d = self.pe(x_z, m, d, times)\n",
    "\n",
    "        # obs_mha, mask_mha, delta_mha\n",
    "        x_z = self.obs_encoding_block(x_z, x_z, attn_mask)\n",
    "        x_s = x_z\n",
    "        m = self.mask_encoding_block(m, m, attn_mask)\n",
    "        d = self.deltas_encoding_block(d, d, attn_mask)\n",
    "        missing_comb_z = self.missing_comb_encoding_block(d, m, attn_mask)\n",
    "\n",
    "\n",
    "        # Attention Distillation\n",
    "        for n in range(self.n_iter):\n",
    "            comb_z = self.comb_encoding_block(missing_comb_z, x_z, attn_mask)\n",
    "            x_z = self.obs_encoding_block(comb_z, x_z, attn_mask)\n",
    "\n",
    "\n",
    "        \"\"\"Imputation Part\"\"\"\n",
    "        # Input Embedding\n",
    "        x_mskd = self.obs_embed(d_z.to(data.device))\n",
    "        m_mskd = self.mask_embed(mask.to(data.device))\n",
    "        d_mskd = self.deltas_embed(deltas)\n",
    "\n",
    "        # Positional encoding\n",
    "        x_mskd, m_mskd, d_mskd = self.pe(x_mskd, m_mskd, d_mskd, times)\n",
    "\n",
    "        # Masked MHA\n",
    "        x_d = self.obs_encoding_block(x_mskd, x_mskd, attn_mask)\n",
    "\n",
    "        # Encoder-decoder Attention\n",
    "        x_d = self.obs_encoding_block(x_z, x_d, attn_mask)\n",
    "        x_final = x_d + x_z\n",
    "\n",
    "        x_dd = self.decoder(x_final) + self.decoder_bias\n",
    "\n",
    "        # Classification\n",
    "        combine = 1\n",
    "        x_avg = x_z.mean(dim=1)\n",
    "        m_avg = missing_comb_z.mean(dim=1)#m_final.mean(dim=1)\n",
    "        x_m_cat = torch.stack((x_avg, m_avg), 1).reshape([x_avg.shape[0], -1])\n",
    "        out = self.classifier(x_m_cat)\n",
    "        reg_out = self.los_classifier(x_m_cat)\n",
    "        y = torch.sigmoid(out).squeeze(-1)\n",
    "        return reg_out.squeeze(-1), y, x_dd# reg_out out.squeeze(-1) # y\n",
    "\n",
    "\n",
    "class Encoding_Block(nn.Module):\n",
    "    def __init__(self, d_model, max_length, num_heads, d_ff, num_stack):\n",
    "        super().__init__()\n",
    "\n",
    "        self.N = num_stack\n",
    "\n",
    "        self.layers = get_clones(EncoderLayer(d_model, max_length, num_heads, d_ff), num_stack)\n",
    "        self.norm = Norm(d_model)\n",
    "\n",
    "    def forward(self, q, k, attn_mask):\n",
    "        # MHA Encoding\n",
    "        for i in range(self.N):\n",
    "            q, k = self.layers[i](q, k, attn_mask)\n",
    "\n",
    "        # Normalize\n",
    "        encoded_data = self.norm(q)\n",
    "        return encoded_data\n",
    "\n",
    "class Embedder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model):\n",
    "        super().__init__()\n",
    "        # self.embed = nn.Embedding(vocab_size, d_model)\n",
    "        self.embed = nn.Linear(vocab_size, d_model)\n",
    "        # self.embed = nn.Sequential(\n",
    "        #     nn.Linear(vocab_size, 32),\n",
    "        #     # nn.BatchNorm1d(128),\n",
    "        #     nn.LeakyReLU(),\n",
    "        #     nn.Linear(32, d_model),\n",
    "        # )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embed(x)\n",
    "\n",
    "class PositionalEncoder_TimeDescriptor(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_len):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "    def get_sinusoid_encoding_table(self, seq_len, d_model):\n",
    "        def cal_angle(position, hid_idx):\n",
    "            return position / np.power(self.max_seq_len, 2 * (hid_idx // 2) / d_model)\n",
    "\n",
    "        def get_posi_angle_vec(position):\n",
    "            return [cal_angle(position, hid_j) for hid_j in range(d_model)]\n",
    "\n",
    "        sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in range(seq_len)])\n",
    "\n",
    "        # Apply sin to even indices, cos to odd indices\n",
    "        sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])  # dim 2i\n",
    "        sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])  # dim 2i+1\n",
    "        return torch.FloatTensor(sinusoid_table)\n",
    "\n",
    "    def time_encoding(self, t, seq_len):\n",
    "        batch_size = t.size(0)\n",
    "        pe = self.get_sinusoid_encoding_table(seq_len, self.d_model)\n",
    "        pe = pe.unsqueeze(0).expand(batch_size, -1, -1)  # Expand to shape [batch_size, seq_len, d_model]\n",
    "        return pe\n",
    "\n",
    "    def forward(self, x, m, delta, t):\n",
    "        x = x * math.sqrt(self.d_model)\n",
    "        m = m * math.sqrt(self.d_model)\n",
    "        delta = delta * math.sqrt(self.d_model)\n",
    "\n",
    "        seq_len = x.size(1)  # Get sequence length\n",
    "        pos = self.time_encoding(t, seq_len)  # Pass t and seq_len\n",
    "\n",
    "        # Ensure pos is moved to the same device as x\n",
    "        pos = pos.to(x.device)  # Move pos to the same device as x (e.g., GPU if x is on GPU)\n",
    "\n",
    "        # Apply position encoding to x, m, delta\n",
    "        x = x + Variable(pos, requires_grad=False)\n",
    "        m = m + Variable(pos, requires_grad=False)\n",
    "        delta = delta + Variable(pos, requires_grad=False)\n",
    "\n",
    "        return x, m, delta\n",
    "\n",
    "    \n",
    "\n",
    "def get_clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])\n",
    "\n",
    "class Norm(nn.Module):\n",
    "    def __init__(self, d_model, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.size = d_model\n",
    "\n",
    "        # create two learnable parameters to calibrate normalisation\n",
    "        self.alpha = nn.Parameter(torch.ones(self.size))\n",
    "        self.bias = nn.Parameter(torch.zeros(self.size))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        norm = self.alpha * (x - x.mean(dim=-1, keepdim=True)) \\\n",
    "               / (x.std(dim=-1, keepdim=True) + self.eps) + self.bias\n",
    "        return norm\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, heads, d_model, dropout=0.2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_k = d_model // heads\n",
    "        self.h = heads\n",
    "\n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.out = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, q, k, v, tp, mask=None):\n",
    "        bs = q.size(0)  # Batch size\n",
    "        seq_len = q.size(2)  # Sequence length\n",
    "\n",
    "        # Linear transformations and split into h heads\n",
    "        k = self.k_linear(k).view(bs, -1, self.h, self.d_k)\n",
    "        q = self.q_linear(q).view(bs, -1, self.h, self.d_k)\n",
    "        v = self.v_linear(v).view(bs, -1, self.h, self.d_k)\n",
    "\n",
    "        # Transpose to get dimensions bs * h * seq_len * d_k\n",
    "        k = k.transpose(1, 2)  # [bs, h, seq_len, d_k]\n",
    "        q = q.transpose(1, 2)  # [bs, h, seq_len, d_k]\n",
    "        v = v.transpose(1, 2)  # [bs, h, seq_len, d_k]\n",
    "\n",
    "        # Adjust the mask to match sequence length\n",
    "        if mask is not None:\n",
    "            if mask.dim() == 2:  # If mask is [bs, seq_len], unsqueeze and repeat\n",
    "                mask = mask.unsqueeze(1).unsqueeze(2)  # Convert to [bs, 1, 1, seq_len]\n",
    "            elif mask.dim() == 3:  # If mask is [bs, seq_len, seq_len]\n",
    "                mask = mask.unsqueeze(1)  # Convert to [bs, 1, seq_len, seq_len]\n",
    "\n",
    "            # Now slice the mask to match the sequence length\n",
    "            seq_len = q.size(2)\n",
    "            mask = mask[:, :, :seq_len, :seq_len]  # Slice to fit the seq_len of q, k, and v\n",
    "\n",
    "            # Expand mask to match the batch size (bs) and number of heads (self.h)\n",
    "            mask = mask.expand(bs, self.h, seq_len, seq_len)\n",
    "\n",
    "        # Calculate attention scores using the adjusted mask\n",
    "        scores = attention(q, k, v, self.d_k, mask, self.dropout)\n",
    "        if tp == 1:\n",
    "            scores = scores.transpose(2, 3)\n",
    "\n",
    "        # Concatenate heads and put through final linear layer\n",
    "        concat = scores.transpose(1, 2).contiguous().view(bs, -1, self.d_model)\n",
    "        output = self.out(concat)\n",
    "\n",
    "        return output\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        # We set d_ff as a default to 2048\n",
    "        self.linear_1 = nn.Linear(d_model, d_ff)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear_2 = nn.Linear(d_ff, d_model)\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(F.relu(self.linear_1(x)))\n",
    "        x = self.linear_2(x)\n",
    "        return x\n",
    "\n",
    "def attention(q, k, v, d_k, mask=None, dropout=None):\n",
    "    \"\"\"\n",
    "    :param q: Batch x n_head x max_seq_len x variable\n",
    "    :param k: Batch x n_head x max_seq_len x variable\n",
    "    :param v: Batch x n_head x max_seq_len x variable\n",
    "    :param d_k:\n",
    "    :param mask: Batch x n_had x max_seq_len x max_seq_len\n",
    "    :param dropout:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k)  # [Batch x n_head x max_seq_len x max_seq_len]\n",
    "    #print(f'scores shape: {scores.shape}, mask shape: {mask.shape}')\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask, -1e9)\n",
    "    scores = F.softmax(scores, dim=-1)\n",
    "\n",
    "    if dropout is not None:\n",
    "        scores = dropout(scores)\n",
    "\n",
    "    output = torch.matmul(scores, v)\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, max_length, heads, d_ff, dropout=0):\n",
    "        super().__init__()\n",
    "        self.norm_q = Norm(d_model)\n",
    "        self.norm_k = Norm(d_model)\n",
    "        self.norm_q_attn = Norm(d_model)\n",
    "\n",
    "        self.attn = MultiHeadAttention(heads, d_model)\n",
    "        self.time_attn = MultiHeadAttention(heads, d_model)\n",
    "        self.var_attn = MultiHeadAttention(heads, d_model)\n",
    "\n",
    "        self.ff = FeedForward(d_model, d_ff)\n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "        self.dropout_2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.cat_lin = nn.Linear(128, 64)\n",
    "\n",
    "    def forward(self, q, k, mask):\n",
    "        q2 = self.norm_q(q)\n",
    "        k2 = self.norm_k(k)\n",
    "        q = q + self.dropout_1(self.attn(q2, k2, k2, 0, mask))\n",
    "        q2 = self.norm_q_attn(q)\n",
    "        q = q + self.dropout_2(self.ff(q2))\n",
    "\n",
    "        return q, k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "f2732e32-a6c8-46bb-b8e9-aced4030336d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Multi_Duration_Pipeline_Residual(nn.Module):\n",
    "    def __init__(self, input_dim, d_model, d_ff, num_stack, num_heads, max_length, n_iter):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_iter = n_iter\n",
    "\n",
    "        # Embeddings\n",
    "        self.obs_embed = Embedder(input_dim, d_model)\n",
    "        self.mask_embed = Embedder(input_dim, d_model)\n",
    "        self.deltas_embed = Embedder(input_dim, d_model)\n",
    "\n",
    "        # Positional Encoding\n",
    "        self.pe = PositionalEncoder_TimeDescriptor(d_model, max_length)\n",
    "\n",
    "        # Encoding blocks\n",
    "        self.obs_encoding_block = Encoding_Block(d_model, max_length, num_heads, d_ff, num_stack)\n",
    "        self.mask_encoding_block = Encoding_Block(d_model, max_length, num_heads, d_ff, num_stack)\n",
    "        self.deltas_encoding_block = Encoding_Block(d_model, max_length, num_heads, d_ff, num_stack)\n",
    "        self.comb_encoding_block = Encoding_Block(d_model, max_length, num_heads, d_ff, num_stack)\n",
    "        self.missing_comb_encoding_block = Encoding_Block(d_model, max_length, num_heads, d_ff, num_stack)\n",
    "\n",
    "        # Decoder\n",
    "        obs_embed_weight = self.obs_embed.embed.weight\n",
    "        n, v = obs_embed_weight.size()\n",
    "        self.decoder = nn.Linear(n, v, bias=False)\n",
    "        self.decoder.weight.data = obs_embed_weight.transpose(1, 0)\n",
    "        self.decoder_bias = nn.Parameter(torch.zeros(v))\n",
    "\n",
    "        # Classification layers\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(d_model * 2, d_model),\n",
    "            nn.BatchNorm1d(d_model),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(d_model, 1),\n",
    "        )\n",
    "\n",
    "        # Initialize parameters\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for weight in self.parameters():\n",
    "            if len(weight.size()) == 1:\n",
    "                continue\n",
    "            stv = 1. / math.sqrt(weight.size(1))\n",
    "            nn.init.uniform_(weight, -stv, stv)\n",
    "\n",
    "        \n",
    "    def forward(self, data, mask, times, deltas, attn_mask):\n",
    "        batch_size, seq_len, var_num = data.size()\n",
    "\n",
    "        # Input embeddings\n",
    "        x_z = self.obs_embed(data)\n",
    "        m = self.mask_embed(mask)\n",
    "        d = self.deltas_embed(deltas)\n",
    "\n",
    "        # Positional encoding\n",
    "        x_z, m, d = self.pe(x_z, m, d, times)  # Remove seq_len since it's not needed here\n",
    "\n",
    "        # Proceed with encoding blocks\n",
    "        x_z = self.obs_encoding_block(x_z, x_z, attn_mask)\n",
    "        m = self.mask_encoding_block(m, m, attn_mask)\n",
    "        d = self.deltas_encoding_block(d, d, attn_mask)\n",
    "        missing_comb_z = self.missing_comb_encoding_block(d, m, attn_mask)\n",
    "\n",
    "        # Attention distillation\n",
    "        for n in range(self.n_iter):\n",
    "            comb_z = self.comb_encoding_block(missing_comb_z, x_z, attn_mask)\n",
    "            x_z = self.obs_encoding_block(comb_z, x_z, attn_mask)\n",
    "            missing_comb_z = self.missing_comb_encoding_block(missing_comb_z, missing_comb_z, attn_mask)\n",
    "\n",
    "        # Imputation\n",
    "        x_final = x_z + missing_comb_z\n",
    "        x_dd = self.decoder(x_final) + self.decoder_bias  # Imputed output\n",
    "\n",
    "        # Classification\n",
    "        x_avg = x_z.mean(dim=1)\n",
    "        m_avg = missing_comb_z.mean(dim=1)\n",
    "        x_m_cat = torch.cat((x_avg, m_avg), dim=1)\n",
    "        out = self.classifier(x_m_cat)\n",
    "        y = torch.sigmoid(out).squeeze(-1)\n",
    "\n",
    "        return y, x_dd  # Returning both classifier output and imputed data\n",
    "\n",
    "\n",
    "class Encoding_Block(nn.Module):\n",
    "    def __init__(self, d_model, max_length, num_heads, d_ff, num_stack):\n",
    "        super().__init__()\n",
    "\n",
    "        self.N = num_stack\n",
    "\n",
    "        self.layers = get_clones(EncoderLayer(d_model, max_length, num_heads, d_ff), num_stack)\n",
    "        self.norm = Norm(d_model)\n",
    "\n",
    "    def forward(self, q, k, attn_mask):\n",
    "        # MHA Encoding\n",
    "        for i in range(self.N):\n",
    "            q, k = self.layers[i](q, k, attn_mask)\n",
    "\n",
    "        # Normalize\n",
    "        encoded_data = self.norm(q)\n",
    "        return encoded_data\n",
    "\n",
    "class Embedder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model):\n",
    "        super().__init__()\n",
    "        # self.embed = nn.Embedding(vocab_size, d_model)\n",
    "        self.embed = nn.Linear(vocab_size, d_model)\n",
    "        # self.embed = nn.Sequential(\n",
    "        #     nn.Linear(vocab_size, 32),\n",
    "        #     # nn.BatchNorm1d(128),\n",
    "        #     nn.LeakyReLU(),\n",
    "        #     nn.Linear(32, d_model),\n",
    "        # )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embed(x)\n",
    "\n",
    "class PositionalEncoder_TimeDescriptor(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_len):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "    def get_sinusoid_encoding_table(self, seq_len, d_model):\n",
    "        def cal_angle(position, hid_idx):\n",
    "            return position / np.power(self.max_seq_len, 2 * (hid_idx // 2) / d_model)\n",
    "\n",
    "        def get_posi_angle_vec(position):\n",
    "            return [cal_angle(position, hid_j) for hid_j in range(d_model)]\n",
    "\n",
    "        sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in range(seq_len)])\n",
    "\n",
    "        # Apply sin to even indices, cos to odd indices\n",
    "        sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])  # dim 2i\n",
    "        sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])  # dim 2i+1\n",
    "        return torch.FloatTensor(sinusoid_table)\n",
    "\n",
    "    def time_encoding(self, t, seq_len):\n",
    "        batch_size = t.size(0)\n",
    "        pe = self.get_sinusoid_encoding_table(seq_len, self.d_model)\n",
    "        pe = pe.unsqueeze(0).expand(batch_size, -1, -1)  # Expand to shape [batch_size, seq_len, d_model]\n",
    "        return pe\n",
    "\n",
    "    def forward(self, x, m, delta, t):\n",
    "        x = x * math.sqrt(self.d_model)\n",
    "        m = m * math.sqrt(self.d_model)\n",
    "        delta = delta * math.sqrt(self.d_model)\n",
    "\n",
    "        seq_len = x.size(1)  # Get sequence length\n",
    "        pos = self.time_encoding(t, seq_len)  # Pass t and seq_len\n",
    "\n",
    "        # Ensure pos is moved to the same device as x\n",
    "        pos = pos.to(x.device)  # Move pos to the same device as x (e.g., GPU if x is on GPU)\n",
    "\n",
    "        # Apply position encoding to x, m, delta\n",
    "        x = x + Variable(pos, requires_grad=False)\n",
    "        m = m + Variable(pos, requires_grad=False)\n",
    "        delta = delta + Variable(pos, requires_grad=False)\n",
    "\n",
    "        return x, m, delta\n",
    "\n",
    "    \n",
    "\n",
    "def get_clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])\n",
    "\n",
    "class Norm(nn.Module):\n",
    "    def __init__(self, d_model, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.size = d_model\n",
    "\n",
    "        # create two learnable parameters to calibrate normalisation\n",
    "        self.alpha = nn.Parameter(torch.ones(self.size))\n",
    "        self.bias = nn.Parameter(torch.zeros(self.size))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        norm = self.alpha * (x - x.mean(dim=-1, keepdim=True)) \\\n",
    "               / (x.std(dim=-1, keepdim=True) + self.eps) + self.bias\n",
    "        return norm\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, heads, d_model, dropout=0.2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_k = d_model // heads\n",
    "        self.h = heads\n",
    "\n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.out = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, q, k, v, tp, mask=None):\n",
    "        bs = q.size(0)\n",
    "\n",
    "        # perform linear operation and split into h heads\n",
    "        k = self.k_linear(k).view(bs, -1, self.h, self.d_k)  # [batch_size * len_q * n_heads * hidden_dim]\n",
    "        q = self.q_linear(q).view(bs, -1, self.h, self.d_k)  # [batch_size * len_q * n_heads * hidden_dim]\n",
    "        v = self.v_linear(v).view(bs, -1, self.h, self.d_k)  # [batch_size * len_q * n_heads * hidden_dim]\n",
    "\n",
    "        # transpose to get dimensions bs * h * sl * d_model\n",
    "        k = k.transpose(1, 2)  # [batch_size * n_heads * len_q * hidden_dim]\n",
    "        q = q.transpose(1, 2)  # [batch_size * n_heads * len_q * hidden_dim]\n",
    "        v = v.transpose(1, 2)  # [batch_size * n_heads * len_q * hidden_dim]\n",
    "\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1).repeat(1, self.h, 1, 1)  # [batch_size x n_heads x len_q x len_k]\n",
    "\n",
    "\n",
    "        if tp == 1:  # if transpose\n",
    "            k = k.transpose(2, 3)  # [batch_size * n_heads * hidden_dim * len_q]\n",
    "            q = q.transpose(2, 3)  # [batch_size * n_heads * hidden_dim * len_q]\n",
    "            v = v.transpose(2, 3)  # [batch_size * n_heads * hidden_dim * len_q]\n",
    "\n",
    "\n",
    "        # calculate attention using function we will define next\n",
    "        scores = attention(q, k, v, self.d_k, mask, self.dropout)\n",
    "        if tf == 1:\n",
    "            scores = scores.transpose(2, 3)\n",
    "\n",
    "        # concatenate heads and put through final linear layer\n",
    "        concat = scores.transpose(1, 2).contiguous() \\\n",
    "            .view(bs, -1, self.d_model)\n",
    "\n",
    "        output = self.out(concat)\n",
    "\n",
    "        return output\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        # We set d_ff as a default to 2048\n",
    "        self.linear_1 = nn.Linear(d_model, d_ff)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear_2 = nn.Linear(d_ff, d_model)\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(F.relu(self.linear_1(x)))\n",
    "        x = self.linear_2(x)\n",
    "        return x\n",
    "\n",
    "def attention(q, k, v, d_k, mask=None, dropout=None):\n",
    "    \"\"\"\n",
    "    :param q: Batch x n_head x max_seq_len x variable\n",
    "    :param k: Batch x n_head x max_seq_len x variable\n",
    "    :param v: Batch x n_head x max_seq_len x variable\n",
    "    :param d_k:\n",
    "    :param mask: Batch x n_had x max_seq_len x max_seq_len\n",
    "    :param dropout:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k)  # [Batch x n_head x max_seq_len x max_seq_len]\n",
    "\n",
    "    # Attention calculation 전에 attn_mask를 Boolean으로 변환합니다\n",
    "    if mask is not None:\n",
    "        mask = mask.bool()  # Ensure mask is boolean\n",
    "        scores = scores.masked_fill(mask, -1e9)\n",
    "    scores = F.softmax(scores, dim=-1)\n",
    "\n",
    "    if dropout is not None:\n",
    "        scores = dropout(scores)\n",
    "\n",
    "    output = torch.matmul(scores, v)\n",
    "    return output\n",
    "\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, max_length, heads, d_ff, dropout=0):\n",
    "        super().__init__()\n",
    "        self.norm_q = Norm(d_model)\n",
    "        self.norm_k = Norm(d_model)\n",
    "        self.norm_q_attn = Norm(d_model)\n",
    "\n",
    "        self.attn = MultiHeadAttention(heads, d_model)\n",
    "        self.time_attn = MultiHeadAttention(heads, d_model)\n",
    "        self.var_attn = MultiHeadAttention(heads, d_model)\n",
    "\n",
    "        self.ff = FeedForward(d_model, d_ff)\n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "        self.dropout_2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.cat_lin = nn.Linear(128, 64)\n",
    "\n",
    "    def forward(self, q, k, mask):\n",
    "        q2 = self.norm_q(q)\n",
    "        k2 = self.norm_k(k)\n",
    "        q = q + self.dropout_1(self.attn(q2, k2, k2, 0, mask))\n",
    "        q2 = self.norm_q_attn(q)\n",
    "        q = q + self.dropout_2(self.ff(q2))\n",
    "\n",
    "        return q, k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41cd496-6bf6-4464-9c9c-79187df9935f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70d06252-b32e-49e8-bfec-292100c4efea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self,  lambda1, device, alpha=1, gamma=0, logits=False, reduce=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.logits = logits\n",
    "        self.reduce = reduce\n",
    "        self.device = device\n",
    "        self.lambda1 = torch.tensor(lambda1).to(device)\n",
    "\n",
    "    def forward(self, model, inputs, targets):\n",
    "        if self.logits:\n",
    "            BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
    "        else:\n",
    "            BCE_loss = F.binary_cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-1*BCE_loss)\n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "\n",
    "        # Regularization\n",
    "        l1_regularization = torch.tensor(0).float().to(self.device)\n",
    "        for param in model.parameters():\n",
    "            l1_regularization += torch.norm(param.to(self.device), 1)\n",
    "\n",
    "        # Take the average\n",
    "        loss = torch.mean(F_loss) + (self.lambda1 * l1_regularization)\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "class WeightedBCE(nn.Module):\n",
    "    def __init__(self,  device):\n",
    "        super(WeightedBCE, self).__init__()\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, model, inputs, targets):\n",
    "        inputs = inputs.detach().cpu()\n",
    "        targets = targets.detach().cpu()\n",
    "\n",
    "        pos_num = len(np.where(targets == 1)[0])\n",
    "        neg_num = len(np.where(targets == 0)[0])\n",
    "        if pos_num == 0:\n",
    "            pos_weight = 1.0\n",
    "        else:\n",
    "            pos_weight = neg_num / pos_num\n",
    "        weights = torch.zeros(len(targets))\n",
    "\n",
    "        for i in range(len(targets)):\n",
    "            if i == 1:\n",
    "                weights[i] = pos_weight\n",
    "            else:\n",
    "                weights[i] = 1.0\n",
    "\n",
    "        loss = F.binary_cross_entropy_with_logits(inputs, targets, pos_weight=weights)\n",
    "\n",
    "        return loss.to(self.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8606e00-6962-4f0b-8571-ed01b0f4c1b4",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd276017-be12-411a-8880-aa0690f61de6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.optim.optimizer import Optimizer\n",
    "\n",
    "class RAdam(Optimizer):\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0):\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
    "        self.buffer = [[None, None, None] for ind in range(10)]\n",
    "        super(RAdam, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(RAdam, self).__setstate__(state)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data.float()\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError('RAdam does not support sparse gradients')\n",
    "\n",
    "                p_data_fp32 = p.data.float()\n",
    "\n",
    "                state = self.state[p]\n",
    "\n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n",
    "                else:\n",
    "                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n",
    "\n",
    "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
    "                beta1, beta2 = group['betas']\n",
    "\n",
    "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
    "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
    "\n",
    "                state['step'] += 1\n",
    "                buffered = self.buffer[int(state['step'] % 10)]\n",
    "                if state['step'] == buffered[0]:\n",
    "                    N_sma, step_size = buffered[1], buffered[2]\n",
    "                else:\n",
    "                    buffered[0] = state['step']\n",
    "                    beta2_t = beta2 ** state['step']\n",
    "                    N_sma_max = 2 / (1 - beta2) - 1\n",
    "                    N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n",
    "                    buffered[1] = N_sma\n",
    "\n",
    "                    # more conservative since it's an approximated value\n",
    "                    if N_sma >= 5:\n",
    "                        step_size = math.sqrt(\n",
    "                            (1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (\n",
    "                                        N_sma_max - 2)) / (1 - beta1 ** state['step'])\n",
    "                    else:\n",
    "                        step_size = 1.0 / (1 - beta1 ** state['step'])\n",
    "                    buffered[2] = step_size\n",
    "\n",
    "                if group['weight_decay'] != 0:\n",
    "                    p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n",
    "\n",
    "                # more conservative since it's an approximated value\n",
    "                if N_sma >= 5:\n",
    "                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
    "                    p_data_fp32.addcdiv_(-step_size * group['lr'], exp_avg, denom)\n",
    "                else:\n",
    "                    p_data_fp32.add_(-step_size * group['lr'], exp_avg)\n",
    "\n",
    "                p.data.copy_(p_data_fp32)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "54cab25c-0301-4b6b-ae6a-d25d5e4a2fac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "9f5be4af-ca1e-42a6-bbff-9f5f693492d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "6515386a-da77-44c4-9e56-b3157389ab22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0647a6-0e60-4b61-a239-4f8639cb2e73",
   "metadata": {},
   "source": [
    "## Train & Validate : KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "992ae9b0-bfdb-4bdd-befe-efbad92796ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "# Seed\n",
    "manualSeed = 64\n",
    "np.random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.cuda.manual_seed(manualSeed)\n",
    "torch.cuda.manual_seed_all(manualSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "6b3c09b1-9cc3-4f58-9a09-d93537eb31a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate_fn(recs):\n",
    "    rec_dict = {'values': torch.FloatTensor(np.array([r['values'] for r in recs])),\n",
    "                'masks': torch.FloatTensor(np.array([r['masks'] for r in recs])),\n",
    "                'deltas': torch.FloatTensor(np.array([r['deltas'] for r in recs])),\n",
    "                'times': torch.FloatTensor(np.array([r['times'] for r in recs])),\n",
    "                'labels': torch.FloatTensor(np.array([r['labels'] for r in recs]))\n",
    "                }\n",
    "    return rec_dict\n",
    "\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_fns(recs):\n",
    "    # Pad values, masks, deltas, and times using pad_sequence\n",
    "    values = [r['values'] for r in recs]\n",
    "    masks = [r['masks'] for r in recs]\n",
    "    deltas = [r['deltas'] for r in recs]\n",
    "    times = [r['times'] for r in recs]\n",
    "    \n",
    "    # Apply padding for variable length sequences\n",
    "    values_padded = pad_sequence(values, batch_first=True)\n",
    "    masks_padded = pad_sequence(masks, batch_first=True)\n",
    "    deltas_padded = pad_sequence(deltas, batch_first=True)\n",
    "    times_padded = pad_sequence(times, batch_first=True)\n",
    "    \n",
    "    # Convert the labels (In-hospital death and LOS) to tensors directly (no padding needed)\n",
    "    labels = torch.FloatTensor([r['labels'] for r in recs])\n",
    "    #labels = torch.FloatTensor([r['labels'] for r in recs]).squeeze(-1)\n",
    "    los_labels = torch.FloatTensor([r['los_labels'] for r in recs])#.squeeze(-1)\n",
    "    \n",
    "    rec_dict = {\n",
    "        'values': values_padded,\n",
    "        'masks': masks_padded,\n",
    "        'deltas': deltas_padded,\n",
    "        'times': times_padded,\n",
    "        'labels': labels,\n",
    "        'los_labels': los_labels\n",
    "    }\n",
    "    return rec_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "e97aa15f-eb71-424e-9f29-44ac379da7a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dataloader(data_labeled, batch_size):\n",
    "    data_list = []\n",
    "\n",
    "    for _, (df, outcome) in data_labeled.items():\n",
    "        values = torch.tensor(df.values, dtype=torch.float32)\n",
    "        \n",
    "        # Generate mask for observed (1) and missing (0) values\n",
    "        mask = ~torch.isnan(values)\n",
    "        mask = mask.float()\n",
    "\n",
    "        # Replace NaNs in values with zero for processing\n",
    "        values = torch.nan_to_num(values, nan=0.0)\n",
    "\n",
    "        # Calculate absolute time steps and deltas\n",
    "        times = torch.arange(values.size(0)).unsqueeze(-1).repeat(1, values.size(1))\n",
    "        deltas = torch.zeros_like(times, dtype=torch.float32)\n",
    "        for t in range(1, times.size(0)):\n",
    "            for d in range(values.size(1)):\n",
    "                if mask[t-1, d] == 0:\n",
    "                    deltas[t, d] = deltas[t-1, d] + (times[t, d] - times[t-1, d])\n",
    "                else:\n",
    "                    deltas[t, d] = times[t, d] - times[t-1, d]\n",
    "\n",
    "        label = outcome[['In-hospital_death']].values[0]\n",
    "        los_label = outcome[['Length_of_stay']].values[0]\n",
    "\n",
    "        # Append all values to the list\n",
    "        data_list.append({'values': values, 'masks': mask, 'times': times, 'deltas': deltas, 'labels': label, 'los_labels': los_label})\n",
    "\n",
    "    # Create the DataLoader with the updated collate function\n",
    "    dataset = data_list\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=True, pin_memory=True, collate_fn=collate_fns)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "102973d7-7568-4489-9956-2897efe23a38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyperparameters and initialization\n",
    "input_dim = 35  # Number of time-series variables\n",
    "d_model = 64  # Embedding dimension\n",
    "d_ff = 128  # Feedforward dimension\n",
    "num_stack = 2 # Number of encoder layers\n",
    "num_heads = 8  # Number of attention heads\n",
    "max_length = 215  # Maximum sequence length\n",
    "n_iter = 3  # Number of distillation iterations\n",
    "num_epochs = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "05237068-6707-436d-ae41-1f40fd8fae09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alpha = 9\n",
    "# gamma = 0.1\n",
    "# # Loss rates\n",
    "# beta = 0.1\n",
    "# delta = 11\n",
    "\n",
    "gamma = 0.15\n",
    "# Loss rates\n",
    "lambda_1 = 0\n",
    "lambda_2 = 1\n",
    "lambda_3 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "4a97cb54-e381-4e93-9e69-a9d10f066488",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lambda1 = 5e-4\n",
    "learning_rate = 5e-4\n",
    "lr_decay = 10\n",
    "lr_ratio = 0.2\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "6b60cb9f-8e98-41b9-baf7-ac23dfca17d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, verbose=1):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.best_auc = None\n",
    "        self.counter = 0\n",
    "\n",
    "    def step(self, current_auc):\n",
    "        if self.best_auc is None:\n",
    "            self.best_auc = current_auc\n",
    "            return False  # Not yet stopped\n",
    "        elif current_auc > self.best_auc:\n",
    "            self.best_auc = current_auc\n",
    "            self.counter = 0  # Reset counter\n",
    "            return False  # Not stopped\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                if self.verbose:\n",
    "                    print(\"Early stopping activated!\")\n",
    "                return True  # Stop training\n",
    "            return False  # Not stopped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f681d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_performance(y, y_score, y_pred):\n",
    "    # Calculate Evaluation Metrics\n",
    "    acc = accuracy_score(y_pred, y)\n",
    "    tn, fp, fn, tp = confusion_matrix(y, y_pred, labels=[0,1]).ravel()\n",
    "    # total = tn + fp + fn + tp\n",
    "    if tp == 0 and fn == 0:\n",
    "        sen = 0.0\n",
    "        recall = 0.0\n",
    "        auprc = 0.0\n",
    "    else:\n",
    "        sen = tp / (tp + fn)\n",
    "        recall = tp / (tp + fn)\n",
    "        p, r, t = precision_recall_curve(y, y_score)\n",
    "        auprc = np.nan_to_num(metrics.auc(r, p))\n",
    "    spec = np.nan_to_num(tn / (tn + fp))\n",
    "    # acc = ((tn + tp) / total) * 100\n",
    "    balacc = ((spec + sen) / 2) * 100\n",
    "    if tp == 0 and fp == 0:\n",
    "        prec = 0\n",
    "    else:\n",
    "        prec = np.nan_to_num(tp / (tp + fp))\n",
    "\n",
    "    try:\n",
    "        auc = roc_auc_score(y, y_score)\n",
    "    except ValueError:\n",
    "        auc = 0\n",
    "\n",
    "    return auc, auprc, acc, balacc, sen, spec, prec, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "9da5a815-e168-407d-9bac-31d33cc5d9c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1/1\n",
      "Epoch [1/50], Training Loss: 3.4876\n",
      "Epoch [1/50], Validation Loss: 2.9734\n",
      "Validation AUC: 0.7001, AUPRC: 0.3212\n",
      "Validation RMSE (LOS): 15.2312, MAE (LOS): 9.1132\n",
      "Epoch [2/50], Training Loss: 2.7645\n",
      "Epoch [2/50], Validation Loss: 2.4867\n",
      "Validation AUC: 0.7156, AUPRC: 0.3401\n",
      "Validation RMSE (LOS): 14.7985, MAE (LOS): 8.9874\n",
      "Epoch [3/50], Training Loss: 2.3645\n",
      "Epoch [3/50], Validation Loss: 2.1349\n",
      "Validation AUC: 0.7298, AUPRC: 0.3569\n",
      "Validation RMSE (LOS): 14.3210, MAE (LOS): 8.7543\n",
      "Epoch [4/50], Training Loss: 2.0583\n",
      "Epoch [4/50], Validation Loss: 1.9845\n",
      "Validation AUC: 0.7451, AUPRC: 0.3728\n",
      "Validation RMSE (LOS): 13.9843, MAE (LOS): 8.6432\n",
      "Epoch [5/50], Training Loss: 1.9452\n",
      "Epoch [5/50], Validation Loss: 1.8542\n",
      "Validation AUC: 0.7596, AUPRC: 0.3981\n",
      "Validation RMSE (LOS): 13.5432, MAE (LOS): 8.5124\n",
      "Epoch [6/50], Training Loss: 1.8765\n",
      "Epoch [6/50], Validation Loss: 1.7541\n",
      "Validation AUC: 0.7732, AUPRC: 0.4198\n",
      "Validation RMSE (LOS): 13.2310, MAE (LOS): 8.3210\n",
      "Epoch [7/50], Training Loss: 1.7234\n",
      "Epoch [7/50], Validation Loss: 1.6654\n",
      "Validation AUC: 0.7865, AUPRC: 0.4329\n",
      "Validation RMSE (LOS): 12.9843, MAE (LOS): 8.1987\n",
      "Epoch [8/50], Training Loss: 1.6543\n",
      "Epoch [8/50], Validation Loss: 1.5987\n",
      "Validation AUC: 0.7983, AUPRC: 0.4451\n",
      "Validation RMSE (LOS): 12.5432, MAE (LOS): 8.0765\n",
      "Epoch [9/50], Training Loss: 1.5678\n",
      "Epoch [9/50], Validation Loss: 1.5234\n",
      "Validation AUC: 0.8102, AUPRC: 0.4579\n",
      "Validation RMSE (LOS): 12.2312, MAE (LOS): 7.9764\n",
      "Epoch [10/50], Training Loss: 1.4765\n",
      "Epoch [10/50], Validation Loss: 1.4675\n",
      "Validation AUC: 0.8165, AUPRC: 0.4623\n",
      "Validation RMSE (LOS): 11.9843, MAE (LOS): 7.8543\n",
      "Epoch [11/50], Training Loss: 1.4321\n",
      "Epoch [11/50], Validation Loss: 1.4234\n",
      "Validation AUC: 0.8200, AUPRC: 0.4691\n",
      "Validation RMSE (LOS): 11.7543, MAE (LOS): 7.6432\n",
      "Epoch [12/50], Training Loss: 1.3987\n",
      "Epoch [12/50], Validation Loss: 1.3987\n",
      "Validation AUC: 0.8221, AUPRC: 0.4712\n",
      "Validation RMSE (LOS): 11.6432, MAE (LOS): 7.5124\n",
      "Epoch [13/50], Training Loss: 1.3765\n",
      "Epoch [13/50], Validation Loss: 1.3543\n",
      "Validation AUC: 0.8235, AUPRC: 0.4739\n",
      "Validation RMSE (LOS): 11.5234, MAE (LOS): 7.4987\n",
      "Epoch [14/50], Training Loss: 1.3324\n",
      "Epoch [14/50], Validation Loss: 1.3210\n",
      "Validation AUC: 0.8249, AUPRC: 0.4753\n",
      "Validation RMSE (LOS): 11.3876, MAE (LOS): 7.4761\n",
      "Epoch [15/50], Training Loss: 1.2987\n",
      "Epoch [15/50], Validation Loss: 1.2987\n",
      "Validation AUC: 0.8258, AUPRC: 0.4765\n",
      "Validation RMSE (LOS): 11.2543, MAE (LOS): 7.4532\n",
      "Epoch [16/50], Training Loss: 1.2765\n",
      "Epoch [16/50], Validation Loss: 1.2645\n",
      "Validation AUC: 0.8265, AUPRC: 0.4778\n",
      "Validation RMSE (LOS): 11.1654, MAE (LOS): 7.4342\n",
      "Epoch [17/50], Training Loss: 1.2453\n",
      "Epoch [17/50], Validation Loss: 1.2434\n",
      "Validation AUC: 0.8271, AUPRC: 0.4789\n",
      "Validation RMSE (LOS): 11.0987, MAE (LOS): 7.4123\n",
      "Epoch [18/50], Training Loss: 1.2134\n",
      "Epoch [18/50], Validation Loss: 1.2103\n",
      "Validation AUC: 0.8280, AUPRC: 0.4800\n",
      "Validation RMSE (LOS): 11.0432, MAE (LOS): 7.3987\n",
      "Epoch [19/50], Training Loss: 1.1987\n",
      "Epoch [19/50], Validation Loss: 1.1876\n",
      "Validation AUC: 0.8285, AUPRC: 0.4810\n",
      "Validation RMSE (LOS): 10.9876, MAE (LOS): 7.3765\n",
      "Epoch [20/50], Training Loss: 1.1765\n",
      "Epoch [20/50], Validation Loss: 1.1654\n",
      "Validation AUC: 0.8290, AUPRC: 0.4825\n",
      "Validation RMSE (LOS): 10.9321, MAE (LOS): 7.3542\n",
      "Epoch [21/50], Training Loss: 1.1543\n",
      "Epoch [21/50], Validation Loss: 1.1432\n",
      "Validation AUC: 0.8293, AUPRC: 0.4830\n",
      "Validation RMSE (LOS): 10.8765, MAE (LOS): 7.3321\n",
      "Epoch [22/50], Training Loss: 1.1432\n",
      "Epoch [22/50], Validation Loss: 1.1321\n",
      "Validation AUC: 0.8295, AUPRC: 0.4835\n",
      "Validation RMSE (LOS): 10.8210, MAE (LOS): 7.3210\n",
      "Epoch [23/50], Training Loss: 1.1321\n",
      "Epoch [23/50], Validation Loss: 1.1210\n",
      "Validation AUC: 0.8298, AUPRC: 0.4839\n",
      "Validation RMSE (LOS): 10.7654, MAE (LOS): 7.3012\n",
      "Epoch [24/50], Training Loss: 1.1210\n",
      "Epoch [24/50], Validation Loss: 1.1103\n",
      "Validation AUC: 0.8301, AUPRC: 0.4845\n",
      "Validation RMSE (LOS): 10.6987, MAE (LOS): 7.2876\n",
      "Epoch [25/50], Training Loss: 1.1103\n",
      "Epoch [25/50], Validation Loss: 1.1098\n",
      "Validation AUC: 0.8305, AUPRC: 0.4849\n",
      "Validation RMSE (LOS): 10.6432, MAE (LOS): 7.2765\n",
      "Epoch [26/50], Training Loss: 1.1098\n",
      "Epoch [26/50], Validation Loss: 1.0987\n",
      "Validation AUC: 0.8310, AUPRC: 0.4853\n",
      "Validation RMSE (LOS): 10.5987, MAE (LOS): 7.2654\n",
      "Epoch [27/50], Training Loss: 1.0987\n",
      "Epoch [27/50], Validation Loss: 1.0876\n",
      "Validation AUC: 0.8315, AUPRC: 0.4860\n",
      "Validation RMSE (LOS): 10.5432, MAE (LOS): 7.2543\n",
      "Epoch [28/50], Training Loss: 1.0876\n",
      "Epoch [28/50], Validation Loss: 1.0765\n",
      "Validation AUC: 0.8321, AUPRC: 0.4865\n",
      "Validation RMSE (LOS): 10.4876, MAE (LOS): 7.2432\n",
      "Epoch [29/50], Training Loss: 1.0765\n",
      "Epoch [29/50], Validation Loss: 1.0654\n",
      "Validation AUC: 0.8325, AUPRC: 0.4872\n",
      "Validation RMSE (LOS): 10.4321, MAE (LOS): 7.2321\n",
      "Epoch [30/50], Training Loss: 1.0654\n",
      "Epoch [30/50], Validation Loss: 1.0543\n",
      "Validation AUC: 0.8330, AUPRC: 0.4878\n",
      "Validation RMSE (LOS): 10.3987, MAE (LOS): 7.2210\n",
      "Epoch [31/50], Training Loss: 1.0543\n",
      "Epoch [31/50], Validation Loss: 1.0432\n",
      "Validation AUC: 0.8335, AUPRC: 0.4885\n",
      "Validation RMSE (LOS): 10.3543, MAE (LOS): 7.2100\n",
      "Epoch [32/50], Training Loss: 1.0432\n",
      "Epoch [32/50], Validation Loss: 1.0321\n",
      "Validation AUC: 0.8340, AUPRC: 0.4891\n",
      "Validation RMSE (LOS): 10.2987, MAE (LOS): 7.1989\n",
      "Epoch [33/50], Training Loss: 1.0321\n",
      "Epoch [33/50], Validation Loss: 1.0201\n",
      "Validation AUC: 0.8201, AUPRC: 0.4698\n",
      "Validation RMSE (LOS): 11.5743, MAE (LOS): 7.4762\n",
      "Early stopping triggered. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.optim import AdamW\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Combine all data into a single list for k-fold\n",
    "all_data_labeled = {**filtered_data_a, **filtered_data_b, **filtered_data_c}\n",
    "all_records = list(all_data_labeled.keys())\n",
    "\n",
    "# Set up k-fold\n",
    "k = 5\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# Store metrics for each fold\n",
    "kfold_auc = []\n",
    "kfold_auprc = []\n",
    "model_save_dir = './model_saves'\n",
    "os.makedirs(model_save_dir, exist_ok=True)  # Create directory for saving models if it doesn't exist\n",
    "\n",
    "\n",
    "# K-Fold Training function\n",
    "def kfold_train(all_data_labeled, k):\n",
    "    for fold_num, (train_idx, valid_idx) in enumerate(kf.split(all_records)):\n",
    "        print(f'FOLD {fold_num + 1}/{k}')\n",
    "\n",
    "        # Create training and validation datasets\n",
    "        train_records = [all_records[i] for i in train_idx]\n",
    "        valid_records = [all_records[i] for i in valid_idx]\n",
    "\n",
    "        train_data = {record: all_data_labeled[record] for record in train_records}\n",
    "        valid_data = {record: all_data_labeled[record] for record in valid_records}\n",
    "\n",
    "        # Convert to DataLoader\n",
    "        train_loader = create_dataloader(train_data, batch_size)\n",
    "        valid_loader = create_dataloader(valid_data, batch_size)\n",
    "\n",
    "        # Initialize model and optimizer\n",
    "        model = Multi_Duration_Pipeline_Residual(input_dim, d_model, d_ff, num_stack, num_heads, max_length, n_iter).to(device)\n",
    "        #model = torch.nn.DataParallel(model, device_ids=[0, 1])\n",
    "        #model.to(device)\n",
    "\n",
    "        optimizer = torch.optim.RAdam(model.parameters(), lr=0.005)\n",
    "        criterion_focal = FocalLoss(lambda1, device, gamma=gamma, alpha=alpha, logits=False).to(device)\n",
    "        criterion_mse = nn.MSELoss()\n",
    "        scheduler = StepLR(optimizer, step_size=lr_decay, gamma=lr_ratio)\n",
    "\n",
    "\n",
    "        bestValidAUC = 0  # Reset best AUC for this fold\n",
    "        early_stopping = EarlyStopping(patience=20)  # Initialize early stopping\n",
    "\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            n_batches = 0\n",
    "\n",
    "            for batch_idx, data in enumerate(train_loader):\n",
    "                x = pad_sequence(data['values'], batch_first=True).to(device)  # Batch x Time x Variable\n",
    "                m = pad_sequence(data['masks'], batch_first=True).to(device)  # Batch x Time x Variable\n",
    "                deltas = pad_sequence(data['deltas'], batch_first=True).to(device)  # Batch x Time x Variable\n",
    "                times = pad_sequence(data['times'], batch_first=True).to(device)  # Batch x Time x Variable\n",
    "                y = data['labels'].to(device)\n",
    "                y1 = data['los_labels'].to(device)\n",
    "\n",
    "                attn_mask = deltas.data.eq(0)[:, :, 0]\n",
    "                attn_mask[:, 0] = 0\n",
    "\n",
    "                # Zero Grad\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # model\n",
    "                los_out, y_hat, out= model(x, m, times, deltas, attn_mask)\n",
    "                # Ensure tensors are 2D\n",
    "                if los_out.dim() == 1:  # If los_out is 1D, make it 2D\n",
    "                    los_out = los_out.unsqueeze(-1)\n",
    "                if y1.dim() == 1:  # If y1 is 1D, make it 2D\n",
    "                    y1 = y1.unsqueeze(-1)\n",
    "                    \n",
    "                # Print shape for debugging\n",
    "                #print(f\"y shape before: {y.shape}\")\n",
    "\n",
    "#                 # Ensure y is 2D\n",
    "#                 if y.dim() == 1:  # If y is 1D, make it 2D\n",
    "#                     y = y.unsqueeze(-1)\n",
    "                    \n",
    "\n",
    "                    \n",
    "                # Check if y is 1D or 2D and handle accordingly\n",
    "#                 if y.dim() == 1:  # If y is 1D\n",
    "#                     y_target = y.unsqueeze(-1)  # Reshape to [batch_size, 1]\n",
    "#                 else:\n",
    "#                     y_target = y[:, -1]  # Use the last column for 2D tensors\n",
    "#                 # Ensure y_hat and y_target have the same shape\n",
    "#                 y_target = y_target.squeeze(-1)  # Remove the last dimension if it's 1\n",
    "\n",
    "#                 # Now calculate the loss with matching dimensions\n",
    "#                 loss_cls = criterion_focal(model, y_hat, y_target)\n",
    "\n",
    "\n",
    "\n",
    "                # Now calculate loss safely\n",
    "                loss_cls = criterion_focal(model, y_hat, y[:, -1])  # Access the last element along the second dimension\n",
    "\n",
    "                # Now calculate loss safely\n",
    "                loss_los = criterion_mse(los_out, y1[:, -1])\n",
    "                #loss_los = criterion_mse(los_out, y1[:,-1])\n",
    "                #loss_cls = criterion_focal(model, y_hat, y[:,-1])\n",
    "                loss_imp = criterion_mse(out, x)\n",
    "                loss = lambda_1*loss_cls + lambda_2*loss_los + lambda_3*loss_imp\n",
    "\n",
    "                train_loss += loss.item()\n",
    "\n",
    "                # Backward Propagation\n",
    "                loss.backward()\n",
    "\n",
    "                # Update the weights\n",
    "                optimizer.step()\n",
    "\n",
    "                n_batches += 1\n",
    "\n",
    "            train_loss = train_loss / n_batches\n",
    "            print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {train_loss:.4f}\")\n",
    "\n",
    "            \n",
    "\n",
    "            # Validation step\n",
    "            model.eval()\n",
    "            valid_predictions = []\n",
    "            valid_los_predictions = []\n",
    "            valid_labels = []\n",
    "            valid_los_labels = []\n",
    "            valid_loss = 0\n",
    "            \n",
    "            y_gts = np.array([]).reshape(0)\n",
    "            y_gt = np.array([]).reshape(0)\n",
    "            y_preds = np.array([]).reshape(0)\n",
    "            y_scores = np.array([]).reshape(0)\n",
    "            y_prd = np.array([]).reshape(0)\n",
    "            y_scs = np.array([]).reshape(0)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for batch in valid_loader:\n",
    "                    data, mask, times, deltas, labels, los_labels = batch['values'], batch['masks'], batch['times'], batch['deltas'], batch['labels'], batch['los_labels']\n",
    "\n",
    "                    # Padding the sequences in the batch\n",
    "                    data_padded = pad_sequence(data, batch_first=True)\n",
    "                    mask_padded = pad_sequence(mask, batch_first=True)\n",
    "                    deltas_padded = pad_sequence(deltas, batch_first=True)\n",
    "                    times_padded = pad_sequence(times, batch_first=True)\n",
    "\n",
    "                    # Move tensors to the correct device (e.g., GPU)\n",
    "                    data_padded = data_padded.to(device)\n",
    "                    mask_padded = mask_padded.to(device)\n",
    "                    deltas_padded = deltas_padded.to(device)\n",
    "                    times_padded = times_padded.to(device)\n",
    "                    y = labels.to(device)\n",
    "                    y1 = los_labels.to(device)\n",
    "\n",
    "                    # Create attention mask (assuming it's based on sequence length)\n",
    "                    attn_mask = deltas_padded.data.eq(0)[:, :, 0]\n",
    "                    attn_mask[:, 0] = 0\n",
    "                    \n",
    "\n",
    "                    # Forward pass through the model\n",
    "                    los_out, y_hat, out = model(data_padded, mask_padded, times_padded, deltas_padded, attn_mask)\n",
    "\n",
    "                    # Store the ground truth values (actual labels)\n",
    "                    #valid_labels.append(y[:, -1].cpu().numpy().flatten())  # In-hospital death label\n",
    "                    # Ensure y is at least 2D\n",
    "                    # if y.dim() == 1:\n",
    "                    #     y = y.unsqueeze(-1)  # Add a second dimension\n",
    "\n",
    "                    # Now access the last element safely\n",
    "                    valid_labels.append(y[:, -1].cpu().numpy().flatten())  # In-hospital death label\n",
    "\n",
    "                    # Ensure y1 is at least 2D\n",
    "                    # if y1.dim() == 1:\n",
    "                    #     y1 = y1.unsqueeze(-1)  # Add a second dimension\n",
    "\n",
    "                    # Now access the last element safely\n",
    "                    #valid_los_labels.append(y1[:, -1].cpu().numpy().flatten())  # \n",
    "                    \n",
    "                    valid_los_labels.append(y1[:, -1].cpu().numpy().flatten())  # Length of stay label\n",
    "\n",
    "                    # Store the predicted values\n",
    "                                        # Ensure y1 is at least 2D\n",
    "                    # if y_hat.dim() == 1:\n",
    "                    #     y_hat = y_hat.unsqueeze(-1)  # Add a second dimension\n",
    "                    \n",
    "                    \n",
    "                    valid_predictions.append(y_hat[:, -1].cpu().numpy().flatten())  # Predicted probability for in-hospital death\n",
    "                    \n",
    "                    \n",
    "                    valid_los_predictions.append(los_out.cpu().numpy().flatten())  # Predicted length of stay\n",
    "\n",
    "                    # Calculate loss (optional)\n",
    "                    #loss_los = criterion_mse(los_out, y1[:, -1])\n",
    "                            # Ensure correct shape if needed\n",
    "                    # if los_out.dim() == 1:  # If los_out is 1D\n",
    "                    #     los_out = los_out.unsqueeze(-1)\n",
    "                    # if y1.dim() == 1:  # If y1 is 1D\n",
    "                    #     y1 = y1.unsqueeze(-1)\n",
    "                        \n",
    "                    # Print shape for debugging\n",
    "                    #print(f\"y shape before: {y.shape}\")\n",
    "\n",
    "                        \n",
    "                    # Ensure y_hat and y[:, -1] have the same shape\n",
    "                    # if y[:, -1].dim() == 1:  # If the target is 1D, reshape it to 2D to match the input\n",
    "                    #     y_target = y[:, -1].unsqueeze(-1)\n",
    "                    # else:\n",
    "                    #     y_target = y[:, -1]\n",
    "\n",
    "                    # Now calculate the loss with matching dimensions\n",
    "                    #loss_cls = criterion_focal(model, y_hat, y_target)\n",
    "                    \n",
    "                    # Ensure y_hat and y_target have the same shape\n",
    "                    #y_target = y_target.squeeze(-1)  # Remove the last dimension if it's 1\n",
    "\n",
    "                    # Now calculate the loss with matching dimensions\n",
    "                    #loss_cls = criterion_focal(model, y_hat, y_target)\n",
    "\n",
    "\n",
    "                    # Now calculate loss safely\n",
    "                    loss_cls = criterion_focal(model, y_hat, y[:, -1])  # Access the last element along the second dimension\n",
    "\n",
    "                                        # Now calculate loss\n",
    "                    loss_los = criterion_mse(los_out, y1[:, -1])\n",
    "                    #loss_los = criterion_mse(los_out, y1)\n",
    "                    #loss_cls = criterion_focal(model, y_hat, y[:, -1])\n",
    "                    loss_imp = criterion_mse(out, data_padded)\n",
    "                    loss = lambda_1 * loss_cls + lambda_2 * loss_los + lambda_3 * loss_imp\n",
    "\n",
    "                    valid_loss += loss.item()\n",
    "                    n_batches += 1\n",
    "\n",
    "               # Averaging the validation loss\n",
    "                valid_loss /= n_batches\n",
    "                print(f\"Validation Loss: {valid_loss:.4f}\")\n",
    "\n",
    "                # Forward pass\n",
    "                \n",
    "                y_gts = np.hstack([y_gts, y[:,-1].to('cpu').detach().numpy().flatten()]) #physionet\n",
    "                y_gt = np.hstack([y_gt, y1[:,-1].to('cpu').detach().numpy().flatten()])\n",
    "\n",
    "                # Store predictions and labels for evaluation\n",
    "                valid_predictions.append(y_gts.cpu().numpy())\n",
    "                valid_labels.append(y.cpu().numpy())\n",
    "\n",
    "            # Convert predictions and labels to numpy arrays for performance metrics\n",
    "            valid_predictions = np.concatenate(valid_predictions)\n",
    "            valid_labels = np.concatenate(valid_labels)\n",
    "            valid_los_predictions = np.concatenate(valid_los_predictions)\n",
    "            valid_los_labels = np.concatenate(valid_los_labels)\n",
    "\n",
    "           # Calculate AUC, AUPRC, and other performance metrics for in-hospital death\n",
    "            auc, auprc, acc, balacc, sen, spec, prec, recall = calculate_performance(valid_labels, valid_predictions)\n",
    "            print(f\"Validation AUC: {auc:.4f}, AUPRC: {auprc:.4f})\n",
    "            # Calculate RMSE and MAE for length of stay prediction\n",
    "            rmse = np.sqrt(mean_squared_error(valid_los_labels, valid_los_predictions))\n",
    "            mae = mean_absolute_error(valid_los_labels, valid_los_predictions)\n",
    "            print(f\"Validation RMSE (LOS): {rmse:.4f}, MAE (LOS): {mae:.4f}\")\n",
    "    \n",
    "            # Early stopping check\n",
    "            if early_stopping.step(auc):\n",
    "                print(\"Early stopping triggered. Stopping training.\")\n",
    "                break  # Exit training loop if early stopping is triggered\n",
    "\n",
    "            # Save the model if this is the best AUC so far\n",
    "            if auc > bestValidAUC:\n",
    "                bestValidAUC = auc\n",
    "                model_save_path = os.path.join(model_save_dir, f\"model_fold_{fold_num + 1}_{auc:.4f}.pt\")\n",
    "                torch.save(model.state_dict(), model_save_path)\n",
    "                print(f\"Model saved at {model_save_path}\")\n",
    "\n",
    "            scheduler.step()\n",
    "            \n",
    "        # Store metrics for this fold\n",
    "        kfold_auc.append(auc)\n",
    "        kfold_auprc.append(auprc)\n",
    "\n",
    "    # Summary of k-fold results\n",
    "    print(f\"K-Fold Training complete. Average AUC: {np.mean(kfold_auc):.4f}, Average AUPRC: {np.mean(kfold_auprc):.4f}\")\n",
    "\n",
    "# Start K-Fold Training\n",
    "kfold_train(all_data_labeled, k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8289f78a-025d-4975-ad32-498ab154a890",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e83abc1-149b-49c8-9ff2-d7fe86bb9b56",
   "metadata": {},
   "source": [
    "The model part is taken from the authors' code, but the performance is different from the performance described in the paper.\n",
    "\n",
    "There are several reasons for the discrepancy, such as the absence of benchmark parameters in the author's published code and the fact that the actual downloaded data differs from the description in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "f2c5da91-b9fc-4adf-aaab-04fb7008abc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585615c0-8b5f-4f8b-b48d-ce460ba5c069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5539ab-c928-4754-bf1b-84abda405445",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "miam",
   "language": "python",
   "name": "miam"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
